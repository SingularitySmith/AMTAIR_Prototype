{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)"
      ],
      "metadata": {
        "id": "lt8-AnebGUXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions --- How to use this notebook:\n",
        "\n",
        "1.   Import Libraries & Install Packages: [Run Section 0.1](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/Public_AMTAIR_Prototype.ipynb#scrollTo=0_1_Import_Libraries_Packages)\n",
        "2.   Connect to GitHub Repository & Load Data files: Run Section 0.2\n",
        "3.   ...\n",
        "4. [Link Text](#cell-id)\n",
        "      Requires:\n",
        "<a name=\"cell-id\"></a>\n",
        "# Heading\n",
        "This is the cell I'm linking to\n",
        "\n"
      ],
      "metadata": {
        "id": "22NBzTxxsnfQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtVFO-s74vI_"
      },
      "source": [
        "# 0.1 Import Libraries & Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y2Egs32Mqek8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e994b508-4cc0-45d4-ff6a-06a12ca16c82",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.1.6)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis) (4.0.5)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9.6->pyvis) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, pyvis\n",
            "Successfully installed jedi-0.19.2 pyvis-0.3.2\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: ipykernel==6.17.1 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.17.1)\n",
            "Requirement already satisfied: ipyparallel==8.8.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (8.8.0)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.5.7 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.5.7)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.32.3)\n",
            "Requirement already satisfied: tornado==6.4.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.4.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (24.0.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (0.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.67.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.19.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (4.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (5.7.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2025.1.31)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.7->google-colab) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook==6.5.7->google-colab) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.7->google-colab) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.7->google-colab) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.13)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook==6.5.7->google-colab) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.7->google-colab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.7->google-colab) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.7->google-colab) (4.13.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.7->google-colab) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.3.1)\n",
            "Collecting pgmpy\n",
            "  Downloading pgmpy-1.0.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.6.0+cu124)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pgmpy) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pgmpy) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.4.0)\n",
            "Collecting pyro-ppl (from pgmpy)\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2025.2)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl->pgmpy)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (4.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->pgmpy)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->pgmpy)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->pgmpy)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->pgmpy)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->pgmpy)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->pgmpy)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->pgmpy)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->pgmpy)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->pgmpy)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->pgmpy)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pgmpy) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pgmpy) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pgmpy) (3.0.2)\n",
            "Downloading pgmpy-1.0.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pyro-api, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pyro-ppl, pgmpy\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pgmpy-1.0.0 pyro-api-0.1.2 pyro-ppl-1.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyvis\n",
        "!pip install --upgrade gspread pandas google-auth google-colab\n",
        "\n",
        "!pip install pgmpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import requests      # For making HTTP requests\n",
        "import io           # For working with in-memory file-like objects\n",
        "\n",
        "import pandas as pd   # For data manipulation\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, display\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import networkx as nx"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lGM3UaQ1esYp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "from pyvis.network import Network"
      ],
      "metadata": {
        "id": "bfRoyYGuexNp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 Connect to GitHub Repository\n",
        "\n",
        "The Public GitHub Repo Url in use:\n",
        "\n",
        "https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/\n",
        "\n",
        "Note:\n",
        "When encountering errors, accessing the data, try using \"RAW\" Urls."
      ],
      "metadata": {
        "id": "2a3VR0fLhJow"
      }
    },
    {
      "source": [
        "# Specify the base repository URL\n",
        "repo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/\"\n",
        "\n",
        "def load_file_from_repo(relative_path):\n",
        "  \"\"\"Loads a file from the specified GitHub repository using a relative path.\"\"\"\n",
        "  file_url = repo_url + relative_path\n",
        "  response = requests.get(file_url)\n",
        "\n",
        "  # Check for bad status codes and print more helpful error messages\n",
        "  if response.status_code == 404:\n",
        "    raise HTTPError(f\"File not found at URL: {file_url}. Check the file path/name and ensure the file is publicly accessible.\", response=response)\n",
        "  else:\n",
        "    response.raise_for_status() # Raise for other error codes\n",
        "\n",
        "  file_object = io.StringIO(response.text)\n",
        "\n",
        "  if relative_path.endswith(\".csv\"):\n",
        "    return pd.read_csv(file_object)\n",
        "  elif relative_path.endswith(\".json\"):\n",
        "    return pd.read_json(file_object)\n",
        "  elif relative_path.endswith(\".md\"):\n",
        "    return file_object.read()  # Return the raw content for .md files\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported file type. Add Support in GitHub Connection in the Second Section of this Python Notebook\")\n",
        "\n",
        "# Load files using relative paths\n",
        "\n",
        "df = load_file_from_repo(\"extracted_data.csv\") # Update if the file path is incorrect\n",
        "\n",
        "md_content = load_file_from_repo(\"ArgDown_TestText.md\")\n",
        "\n",
        "# print(df.head()) # To see the output, run the code.\n",
        "\n",
        "print(md_content) # To see the output, run the code."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5yTj7I_5hvB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d938aaac-eef7-4f3a-ebbb-bd93a63157fd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Main Argument: Current AI as Existential Risk Factor\n",
            "\n",
            "<AI_Existential_Risk_Factor>: Current and near-term AI technologies can contribute to existential risk by acting as intermediate risk factors.\n",
            "  + <AI_Intermediate_Factor>: Current and near-term AI technologies can act as intermediate risk factors, magnifying the likelihood of previously identified sources of existential risk.\n",
            "  + <Risk_Not_Limited_To_AGI>: This potential contribution to existential risk is not limited to the unaligned AGI scenario.\n",
            "  + <Causal_Pathways_Exist>: There exist causal pathways from AI systems to existential risks that do not presuppose hypothetical future AI capabilities.\n",
            "\n",
            "\n",
            "# Power Dynamics Arguments\n",
            "\n",
            "[AI_Affects_Power_Dynamics]: AI can shift or strengthen existing power dynamics between different actors.\n",
            "  + [AI_State_State_Risk]: AI can disturb relationships between nation states, potentially leading to an \"AI arms race.\"\n",
            "  + [AI_State_Corporation_Risk]: The rise of tech corporations affects their relationships with states, creating power imbalances.\n",
            "  + [AI_State_Citizen_Risk]: AI surveillance technologies change the dynamics between states and citizens.\n",
            "   /* => [AI_Existential_Risk_Factor]*/\n",
            "\n",
            "## State-State Relationships\n",
            "\n",
            "[AI_State_State_Risk]: AI affects relationships between states in ways that can increase existential risk./*=> [AI_Affects_Power_Dynamics]*/\n",
            " + <AI_Global_Power_Shift>: AI development contributes to a global shift in power towards nations like China (\"Easternisation\").\n",
            " + <AI_Arms_Race>: Concerns about technological competition can lead to an \"AI arms race\" between nations.\n",
            " + <Competition_Inhibits_Coordination>: Such competitive dynamics may inhibit international coordination and incentivize against AI safety precautions.\n",
            "\n",
            "\n",
            "## State-Corporation Relationships\n",
            "\n",
            "[AI_State_Corporation_Risk]: AI affects relationships between states and corporations in ways that can increase existential risk.\n",
            " + <Tech_Corporation_Rise>: The past two decades have seen a monumental rise of private corporations in the technology sector with revenues comparable to national GDPs.\n",
            " + <Corporate_Global_Reach>: These corporations operate globally, making state regulation challenging.\n",
            " + <Profit_Driven_Goals>: Many corporate goals are profit-driven and can be misaligned with wider societal interests.\n",
            "\n",
            "\n",
            "## State-Citizen Relationships\n",
            "\n",
            "[AI_State_Citizen_Risk]: AI surveillance technologies enable potential stable repressive regimes that could constitute existential catastrophes.\n",
            "/* \n",
            "(4) => [AI_Affects_Power_Dynamics]\n",
            "*/\n",
            " + <AI_Surveillance_Growth>: There's been a rapid increase in the use of AI surveillance systems by states across different political systems.\n",
            " + <Insufficient_Ethical_Frameworks>: Ethical and legal frameworks for these technologies are lagging behind their deployment.\n",
            " + <Surveillance_Privatization>: Private companies develop and sell surveillance technologies to governments, further normalizing mass surveillance.\n",
            "\n",
            "<AI_Existential_Risk_Factor>\n",
            "\n",
            "(1) [AI_State_State_Risk]\n",
            "(2) [AI_Affects_Power_Dynamics]\n",
            "--\n",
            "Some inference rule: p .^. (p .->. q) .->. q {some_additional_data: [1,2]}\n",
            "--\n",
            "(3) [AI_Existential_Risk_Factor_Final]\n",
            "  -> Outgoing relations of the conclusion, are also interpreted as outgoing relations of the whole argument.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "# Specific Existential Risk Pathways\n",
            "\n",
            "## Nuclear Risk\n",
            "\n",
            "<Nuclear_Risk_Argument>:\n",
            "  + <AI_State_State_Risk>: AI affects relationships between states, potentially creating tensions.\n",
            "  +  <AI_Arms_Race_To_Military>: An AI arms race could become military in nature.\n",
            "  + <Cybersecurity_Intelligence_Impact>: Changes in cybersecurity could affect a state's intelligence capabilities.\n",
            "/* \n",
            "(4) [AI_Nuclear_Risk]: AI could increase the probability of a nuclear conflict leading to \"nuclear winter\" and potential human extinction. => [AI_Existential_Risk_Factor]\n",
            "*/\n",
            "\n",
            "## Pandemic Risk\n",
            "\n",
            "<Pandemic_Risk_Argument>: \n",
            "  + <AI_Information_Ecosystem_Risk>: AI threatens the information ecosystem, as seen with COVID-19 misinformation.\n",
            "  + <Response_Requires_Trust>: Effective pandemic response requires public trust in political systems.\n",
            "  + <AI_Biological_Weapons>: AI could be used to design and produce dangerous pathogens.\n",
            "\n",
            "/* \n",
            "(4) [AI_Pandemic_Risk]: AI could increase the risk from engineered pandemics and biotechnology. => [AI_Existential_Risk_Factor]\n",
            "*/\n",
            "\n",
            "## Climate Risk\n",
            "\n",
            "<Climate_Risk_Argument>:\n",
            "  + <AI_Information_Ecosystem_Risk>: AI threatens the information ecosystem through misinformation.\n",
            "  +  <Climate_Misinformation>: Climate change has a history of being clouded by misinformation.\n",
            "  +  <AI_Energy_Consumption>: AI development and training has a significant carbon footprint, with a single NLP model producing 300,000kg of CO2 emissions.\n",
            "\n",
            "/* \n",
            "(4) [AI_Climate_Risk]: AI could increase the risk from climate change through both information distortion and direct emissions. => [AI_Existential_Risk_Factor]\n",
            "*/\n",
            "\n",
            "\n",
            "## Unaligned AGI Risk\n",
            "\n",
            "<AGI_Risk_Argument>:\n",
            "  + <AI_Arms_Race>: Concerns about technological competition can lead to an \"AI arms race\" between nations or corporations.\n",
            "  + <Safety_Corner_Cutting>: Competitive dynamics may incentivize corner-cutting on AI safety.\n",
            "\n",
            "/* \n",
            "(3) [AI_AGI_Risk]: Current AI development patterns could increase future risks from unaligned AGI. => [AI_Existential_Risk_Factor]\n",
            "*/\n",
            "\n",
            "\n",
            "## Stable Repressive Regime Risk\n",
            "\n",
            "\n",
            "<Repressive_Regime_Argument>:\n",
            "  + <AI_Surveillance_Growth>: Rapid increase in AI surveillance technologies globally.\n",
            "  + <Lagging_Ethical_Frameworks>: Even democratic countries fail to meet regulatory standards for surveillance.\n",
            "  + <Surveillance_Privatization>: Private-public partnerships normalize surveillance beyond legal limits.\n",
            "\n",
            "/* \n",
            "(4) [AI_Repressive_Regime_Risk]: AI surveillance enables potentially stable, global repressive autocracies constituting existential catastrophes. => [AI_Existential_Risk_Factor]\n",
            "*/\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/* \n",
            "From: Current and Near-Term AI as a Potential Existential Risk Factor by Benjamin S. Bucknall∗\n",
            "*/\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head()) # To see the output, run the code."
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySUTqVpFjVt2",
        "outputId": "b1af6483-05a3-48d9-a239-52994c41d168"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Title                                        Description  line  \\\n",
            "0  Grass_Wet  Concentrated moisture on, between and around t...     3   \n",
            "1       Rain  Tears of angles crying high up in the skies hi...     4   \n",
            "2  Sprinkler  Activation of a centrifugal force based CO2 dr...     5   \n",
            "\n",
            "  line_numbers  indentation indentation_levels                Parents  \\\n",
            "0          [3]            0                [0]  ['Rain', 'Sprinkler']   \n",
            "1       [4, 6]            2             [1, 2]                     []   \n",
            "2          [5]            1                [1]               ['Rain']   \n",
            "\n",
            "                     Children                         instantiations  \\\n",
            "0                          []  ['grass_wet_TRUE', 'grass_wet_FALSE']   \n",
            "1  ['Grass_Wet', 'Sprinkler']            ['rain_TRUE', 'rain_FALSE']   \n",
            "2               ['Grass_Wet']  ['sprinkler_TRUE', 'sprinkler_FALSE']   \n",
            "\n",
            "                                              priors  \\\n",
            "0  {'p(grass_wet_TRUE)': '0.322', 'p(grass_wet_FA...   \n",
            "1    {'p(rain_TRUE)': '0.2', 'p(rain_FALSE)': '0.8'}   \n",
            "2  {'p(sprinkler_TRUE)': '0.44838', 'p(sprinkler_...   \n",
            "\n",
            "                                          posteriors  No_Parent  No_Children  \n",
            "0  {'p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)':...      False         True  \n",
            "1                                                 {}       True        False  \n",
            "2  {'p(sprinkler_TRUE|rain_TRUE)': '0.01', 'p(spr...      False        False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-ix4Rp5fE9m"
      },
      "source": [
        "# 0.3 File Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "FU8FLHpWDxNG",
        "outputId": "42238471-d717-4888-f32c-ddc8fb00d2c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Main Argument: Current AI as Existential Risk Factor\\n\\n<AI_Existential_Risk_Factor>: Current and near-term AI technologies can contribute to existential risk by acting as intermediate risk factors.\\n  + <AI_Intermediate_Factor>: Current and near-term AI technologies can act as intermediate risk factors, magnifying the likelihood of previously identified sources of existential risk.\\n  + <Risk_Not_Limited_To_AGI>: This potential contribution to existential risk is not limited to the unaligned AGI scenario.\\n  + <Causal_Pathways_Exist>: There exist causal pathways from AI systems to existential risks that do not presuppose hypothetical future AI capabilities.\\n\\n\\n# Power Dynamics Arguments\\n\\n[AI_Affects_Power_Dynamics]: AI can shift or strengthen existing power dynamics between different actors.\\n  + [AI_State_State_Risk]: AI can disturb relationships between nation states, potentially leading to an \"AI arms race.\"\\n  + [AI_State_Corporation_Risk]: The rise of tech corporations affects their relationships with states, creating power imbalances.\\n  + [AI_State_Citizen_Risk]: AI surveillance technologies change the dynamics between states and citizens.\\n   /* => [AI_Existential_Risk_Factor]*/\\n\\n## State-State Relationships\\n\\n[AI_State_State_Risk]: AI affects relationships between states in ways that can increase existential risk./*=> [AI_Affects_Power_Dynamics]*/\\n + <AI_Global_Power_Shift>: AI development contributes to a global shift in power towards nations like China (\"Easternisation\").\\n + <AI_Arms_Race>: Concerns about technological competition can lead to an \"AI arms race\" between nations.\\n + <Competition_Inhibits_Coordination>: Such competitive dynamics may inhibit international coordination and incentivize against AI safety precautions.\\n\\n\\n## State-Corporation Relationships\\n\\n[AI_State_Corporation_Risk]: AI affects relationships between states and corporations in ways that can increase existential risk.\\n + <Tech_Corporation_Rise>: The past two decades have seen a monumental rise of private corporations in the technology sector with revenues comparable to national GDPs.\\n + <Corporate_Global_Reach>: These corporations operate globally, making state regulation challenging.\\n + <Profit_Driven_Goals>: Many corporate goals are profit-driven and can be misaligned with wider societal interests.\\n\\n\\n## State-Citizen Relationships\\n\\n[AI_State_Citizen_Risk]: AI surveillance technologies enable potential stable repressive regimes that could constitute existential catastrophes.\\n/* \\n(4) => [AI_Affects_Power_Dynamics]\\n*/\\n + <AI_Surveillance_Growth>: There\\'s been a rapid increase in the use of AI surveillance systems by states across different political systems.\\n + <Insufficient_Ethical_Frameworks>: Ethical and legal frameworks for these technologies are lagging behind their deployment.\\n + <Surveillance_Privatization>: Private companies develop and sell surveillance technologies to governments, further normalizing mass surveillance.\\n\\n<AI_Existential_Risk_Factor>\\n\\n(1) [AI_State_State_Risk]\\n(2) [AI_Affects_Power_Dynamics]\\n--\\nSome inference rule: p .^. (p .->. q) .->. q {some_additional_data: [1,2]}\\n--\\n(3) [AI_Existential_Risk_Factor_Final]\\n  -> Outgoing relations of the conclusion, are also interpreted as outgoing relations of the whole argument.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n# Specific Existential Risk Pathways\\n\\n## Nuclear Risk\\n\\n<Nuclear_Risk_Argument>:\\n  + <AI_State_State_Risk>: AI affects relationships between states, potentially creating tensions.\\n  +  <AI_Arms_Race_To_Military>: An AI arms race could become military in nature.\\n  + <Cybersecurity_Intelligence_Impact>: Changes in cybersecurity could affect a state\\'s intelligence capabilities.\\n/* \\n(4) [AI_Nuclear_Risk]: AI could increase the probability of a nuclear conflict leading to \"nuclear winter\" and potential human extinction. => [AI_Existential_Risk_Factor]\\n*/\\n\\n## Pandemic Risk\\n\\n<Pandemic_Risk_Argument>: \\n  + <AI_Information_Ecosystem_Risk>: AI threatens the information ecosystem, as seen with COVID-19 misinformation.\\n  + <Response_Requires_Trust>: Effective pandemic response requires public trust in political systems.\\n  + <AI_Biological_Weapons>: AI could be used to design and produce dangerous pathogens.\\n\\n/* \\n(4) [AI_Pandemic_Risk]: AI could increase the risk from engineered pandemics and biotechnology. => [AI_Existential_Risk_Factor]\\n*/\\n\\n## Climate Risk\\n\\n<Climate_Risk_Argument>:\\n  + <AI_Information_Ecosystem_Risk>: AI threatens the information ecosystem through misinformation.\\n  +  <Climate_Misinformation>: Climate change has a history of being clouded by misinformation.\\n  +  <AI_Energy_Consumption>: AI development and training has a significant carbon footprint, with a single NLP model producing 300,000kg of CO2 emissions.\\n\\n/* \\n(4) [AI_Climate_Risk]: AI could increase the risk from climate change through both information distortion and direct emissions. => [AI_Existential_Risk_Factor]\\n*/\\n\\n\\n## Unaligned AGI Risk\\n\\n<AGI_Risk_Argument>:\\n  + <AI_Arms_Race>: Concerns about technological competition can lead to an \"AI arms race\" between nations or corporations.\\n  + <Safety_Corner_Cutting>: Competitive dynamics may incentivize corner-cutting on AI safety.\\n\\n/* \\n(3) [AI_AGI_Risk]: Current AI development patterns could increase future risks from unaligned AGI. => [AI_Existential_Risk_Factor]\\n*/\\n\\n\\n## Stable Repressive Regime Risk\\n\\n\\n<Repressive_Regime_Argument>:\\n  + <AI_Surveillance_Growth>: Rapid increase in AI surveillance technologies globally.\\n  + <Lagging_Ethical_Frameworks>: Even democratic countries fail to meet regulatory standards for surveillance.\\n  + <Surveillance_Privatization>: Private-public partnerships normalize surveillance beyond legal limits.\\n\\n/* \\n(4) [AI_Repressive_Regime_Risk]: AI surveillance enables potentially stable, global repressive autocracies constituting existential catastrophes. => [AI_Existential_Risk_Factor]\\n*/\\n\\n\\n\\n\\n/* \\nFrom: Current and Near-Term AI as a Potential Existential Risk Factor by Benjamin S. Bucknall∗\\n*/\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "md_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "MgxYW5al-e0u",
        "outputId": "9008fc68-9f4f-46af-d545-3206ff0a0ad4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Main Argument: Current AI as Existential Risk Factor\n\n<AI_Existential_Risk_Factor>: Current and near-term AI technologies can contribute to existential risk by acting as intermediate risk factors.\n  + <AI_Intermediate_Factor>: Current and near-term AI technologies can act as intermediate risk factors, magnifying the likelihood of previously identified sources of existential risk.\n  + <Risk_Not_Limited_To_AGI>: This potential contribution to existential risk is not limited to the unaligned AGI scenario.\n  + <Causal_Pathways_Exist>: There exist causal pathways from AI systems to existential risks that do not presuppose hypothetical future AI capabilities.\n\n\n# Power Dynamics Arguments\n\n[AI_Affects_Power_Dynamics]: AI can shift or strengthen existing power dynamics between different actors.\n  + [AI_State_State_Risk]: AI can disturb relationships between nation states, potentially leading to an \"AI arms race.\"\n  + [AI_State_Corporation_Risk]: The rise of tech corporations affects their relationships with states, creating power imbalances.\n  + [AI_State_Citizen_Risk]: AI surveillance technologies change the dynamics between states and citizens.\n   /* => [AI_Existential_Risk_Factor]*/\n\n## State-State Relationships\n\n[AI_State_State_Risk]: AI affects relationships between states in ways that can increase existential risk./*=> [AI_Affects_Power_Dynamics]*/\n + <AI_Global_Power_Shift>: AI development contributes to a global shift in power towards nations like China (\"Easternisation\").\n + <AI_Arms_Race>: Concerns about technological competition can lead to an \"AI arms race\" between nations.\n + <Competition_Inhibits_Coordination>: Such competitive dynamics may inhibit international coordination and incentivize against AI safety precautions.\n\n\n## State-Corporation Relationships\n\n[AI_State_Corporation_Risk]: AI affects relationships between states and corporations in ways that can increase existential risk.\n + <Tech_Corporation_Rise>: The past two decades have seen a monumental rise of private corporations in the technology sector with revenues comparable to national GDPs.\n + <Corporate_Global_Reach>: These corporations operate globally, making state regulation challenging.\n + <Profit_Driven_Goals>: Many corporate goals are profit-driven and can be misaligned with wider societal interests.\n\n\n## State-Citizen Relationships\n\n[AI_State_Citizen_Risk]: AI surveillance technologies enable potential stable repressive regimes that could constitute existential catastrophes.\n/* \n(4) => [AI_Affects_Power_Dynamics]\n*/\n + <AI_Surveillance_Growth>: There's been a rapid increase in the use of AI surveillance systems by states across different political systems.\n + <Insufficient_Ethical_Frameworks>: Ethical and legal frameworks for these technologies are lagging behind their deployment.\n + <Surveillance_Privatization>: Private companies develop and sell surveillance technologies to governments, further normalizing mass surveillance.\n\n<AI_Existential_Risk_Factor>\n\n(1) [AI_State_State_Risk]\n(2) [AI_Affects_Power_Dynamics]\n--\nSome inference rule: p .^. (p .->. q) .->. q {some_additional_data: [1,2]}\n--\n(3) [AI_Existential_Risk_Factor_Final]\n  -> Outgoing relations of the conclusion, are also interpreted as outgoing relations of the whole argument.\n\n\n\n\n\n\n\n\n\n# Specific Existential Risk Pathways\n\n## Nuclear Risk\n\n<Nuclear_Risk_Argument>:\n  + <AI_State_State_Risk>: AI affects relationships between states, potentially creating tensions.\n  +  <AI_Arms_Race_To_Military>: An AI arms race could become military in nature.\n  + <Cybersecurity_Intelligence_Impact>: Changes in cybersecurity could affect a state's intelligence capabilities.\n/* \n(4) [AI_Nuclear_Risk]: AI could increase the probability of a nuclear conflict leading to \"nuclear winter\" and potential human extinction. => [AI_Existential_Risk_Factor]\n*/\n\n## Pandemic Risk\n\n<Pandemic_Risk_Argument>: \n  + <AI_Information_Ecosystem_Risk>: AI threatens the information ecosystem, as seen with COVID-19 misinformation.\n  + <Response_Requires_Trust>: Effective pandemic response requires public trust in political systems.\n  + <AI_Biological_Weapons>: AI could be used to design and produce dangerous pathogens.\n\n/* \n(4) [AI_Pandemic_Risk]: AI could increase the risk from engineered pandemics and biotechnology. => [AI_Existential_Risk_Factor]\n*/\n\n## Climate Risk\n\n<Climate_Risk_Argument>:\n  + <AI_Information_Ecosystem_Risk>: AI threatens the information ecosystem through misinformation.\n  +  <Climate_Misinformation>: Climate change has a history of being clouded by misinformation.\n  +  <AI_Energy_Consumption>: AI development and training has a significant carbon footprint, with a single NLP model producing 300,000kg of CO2 emissions.\n\n/* \n(4) [AI_Climate_Risk]: AI could increase the risk from climate change through both information distortion and direct emissions. => [AI_Existential_Risk_Factor]\n*/\n\n\n## Unaligned AGI Risk\n\n<AGI_Risk_Argument>:\n  + <AI_Arms_Race>: Concerns about technological competition can lead to an \"AI arms race\" between nations or corporations.\n  + <Safety_Corner_Cutting>: Competitive dynamics may incentivize corner-cutting on AI safety.\n\n/* \n(3) [AI_AGI_Risk]: Current AI development patterns could increase future risks from unaligned AGI. => [AI_Existential_Risk_Factor]\n*/\n\n\n## Stable Repressive Regime Risk\n\n\n<Repressive_Regime_Argument>:\n  + <AI_Surveillance_Growth>: Rapid increase in AI surveillance technologies globally.\n  + <Lagging_Ethical_Frameworks>: Even democratic countries fail to meet regulatory standards for surveillance.\n  + <Surveillance_Privatization>: Private-public partnerships normalize surveillance beyond legal limits.\n\n/* \n(4) [AI_Repressive_Regime_Risk]: AI surveillance enables potentially stable, global repressive autocracies constituting existential catastrophes. => [AI_Existential_Risk_Factor]\n*/\n\n\n\n\n/* \nFrom: Current and Near-Term AI as a Potential Existential Risk Factor by Benjamin S. Bucknall∗\n*/\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(md_content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52XyPlte5HrU"
      },
      "source": [
        "# 1.0 Sources (PDF's of Papers) to ArgDown (.md file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SGB0XMp5VFq"
      },
      "source": [
        "# 2.0 Probability Extractions: ArgDown (.md) to BayesDown (.md + plugin JSON syntax)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6r95Nm6xk1KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ9OIyEv5qqb"
      },
      "source": [
        "# 3.0 Data Extraction: BayesDown (.md) to Database (.csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFnu_1Ludahi"
      },
      "source": [
        "### 3.1 ExtractBayesDown-Data_v1\n",
        "Build data frame with extractable information from BayesDown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ka4kLU_sj4nH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c9a90bcf-9961-4598-cb3f-5c01cb0bdef4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'## BayesDown Example\\n\\n\\n[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"], \"priors\": {\"p(grass_wet_TRUE)\": \"0.322\",\"p(grass_wet_FALSE)\": \"0.678\"},\"posteriors\": {\"p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)\": \"0.99\",\"p(grass_wet_TRUE|sprinkler_TRUE,rain_FALSE)\": \"0.9\",\"p(grass_wet_TRUE|sprinkler_FALSE,rain_TRUE)\": \"0.8\",\"p(grass_wet_TRUE|sprinkler_FALSE,rain_FALSE)\": \"0.0\",\"p(grass_wet_FALSE|sprinkler_TRUE,rain_TRUE)\": \"0.01\",\"p(grass_wet_FALSE|sprinkler_TRUE,rain_FALSE)\": \"0.1\",\"p(grass_wet_FALSE|sprinkler_FALSE,rain_TRUE)\": \"0.2\",\"p(grass_wet_FALSE|sprinkler_FALSE,rain_FALSE)\": \"1.0\"}}\\n + [Rain]: Tears of angles crying high up in the skies hitting the ground.{\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"],\"priors\": {\"p(rain_TRUE)\": \"0.2\",\"p(rain_FALSE)\": \"0.8\"},\"posteriors\": {}}\\n + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.{\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"],\"priors\": {\"p(sprinkler_TRUE)\": \"0.44838\",\"p(sprinkler_FALSE)\": \"0.55162\"},\"posteriors\": {\"p(sprinkler_TRUE|rain_TRUE)\": \"0.01\",\"p(sprinkler_TRUE|rain_FALSE)\": \"0.4\",\"p(sprinkler_FALSE|rain_TRUE)\": \"0.99\",\"p(sprinkler_FALSE|rain_FALSE)\":\"0.6\"}}\\n  + [Rain]\\n\\n\\n/* ArgDown is extremely sensitive w.r.t. syntax. If there are mistakes, eg. double \"\" instead of single \" or brackets or indentation are off or with the wrong indentation, ArgDown will not compile!*/\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# read sprinkler example -- Occam Colab Online\n",
        "file_path_ex_rain = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/BayesDown_Example.md\"\n",
        "\n",
        "# Use requests.get to fetch content from URL\n",
        "response = requests.get(file_path_ex_rain)\n",
        "response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "# Read content from the response\n",
        "md_content_ex_rain = response.text\n",
        "\n",
        "md_content_ex_rain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1.2 Test BayesDown Extraction\n",
        "\n",
        "Copy and paste the BayesDown formatted ... in the ArgDown Sandbox below to quickly verify that the network renders correctly."
      ],
      "metadata": {
        "id": "eUBJh8Qp4yd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import IFrame\n",
        "\n",
        "# IFrame(src=\"https://argdown.org/sandbox/map/\", width=\"100%\", height=\"600px\")"
      ],
      "metadata": {
        "id": "7_jAnBjf4e4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(md_content_ex_rain)) # view BayesDown file formatted as MarkDown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "xSGQt9Td6XI2",
        "outputId": "e9bb768e-0c14-43b0-cf0b-f99a620a9a32"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## BayesDown Example\n\n\n[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"], \"priors\": {\"p(grass_wet_TRUE)\": \"0.322\",\"p(grass_wet_FALSE)\": \"0.678\"},\"posteriors\": {\"p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)\": \"0.99\",\"p(grass_wet_TRUE|sprinkler_TRUE,rain_FALSE)\": \"0.9\",\"p(grass_wet_TRUE|sprinkler_FALSE,rain_TRUE)\": \"0.8\",\"p(grass_wet_TRUE|sprinkler_FALSE,rain_FALSE)\": \"0.0\",\"p(grass_wet_FALSE|sprinkler_TRUE,rain_TRUE)\": \"0.01\",\"p(grass_wet_FALSE|sprinkler_TRUE,rain_FALSE)\": \"0.1\",\"p(grass_wet_FALSE|sprinkler_FALSE,rain_TRUE)\": \"0.2\",\"p(grass_wet_FALSE|sprinkler_FALSE,rain_FALSE)\": \"1.0\"}}\n + [Rain]: Tears of angles crying high up in the skies hitting the ground.{\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"],\"priors\": {\"p(rain_TRUE)\": \"0.2\",\"p(rain_FALSE)\": \"0.8\"},\"posteriors\": {}}\n + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.{\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"],\"priors\": {\"p(sprinkler_TRUE)\": \"0.44838\",\"p(sprinkler_FALSE)\": \"0.55162\"},\"posteriors\": {\"p(sprinkler_TRUE|rain_TRUE)\": \"0.01\",\"p(sprinkler_TRUE|rain_FALSE)\": \"0.4\",\"p(sprinkler_FALSE|rain_TRUE)\": \"0.99\",\"p(sprinkler_FALSE|rain_FALSE)\":\"0.6\"}}\n  + [Rain]\n\n\n/* ArgDown is extremely sensitive w.r.t. syntax. If there are mistakes, eg. double \"\" instead of single \" or brackets or indentation are off or with the wrong indentation, ArgDown will not compile!*/\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "# read basic ArgDown example With BayesDown syntax added and corss generational added -- Ella\n",
        "import requests  # Import the requests library\n",
        "\n",
        "# **Corrected URL with /main/**\n",
        "file_path_easy_ex_B_CG = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/Example_file_combined_withBayesDown_Crossgenerational.md\"\n",
        "\n",
        "# Use requests.get to fetch content from URL\n",
        "response = requests.get(file_path_easy_ex_B_CG)\n",
        "response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "# Read content from the response\n",
        "md_content_easy_ex_B_CG = response.text\n",
        "\n",
        "md_content_easy_ex_B_CG"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "-HY7vlL3mVJu",
        "outputId": "cf69a2d4-fb14-435b-f1c6-aff3d4f1c97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Unconnected titles with descriptions\\n\\n<a>: I am currently in no relation.\\n\\n<b>: It\\'s complicated.\\n\\n<c>: I feel disconnected.\\n\\n# Two generation connected arguments\\n\\n[Thesis]: Censorship is not wrong in principle.\\n + <P1a>: Freedom of speech is never an absolute right but an aspiration. It ceases to be a right when it causes harm to others. Therefore it is not the case that censorship is wrong in principle.{\"instantiations\": [\"TRUE\", \"FALSE\"],\"priors\": {\"p(TRUE)\": \"0.322\", \"p(FALSE)\": \"0.678\"}, \"posteriors\": {\"p(grass_wet|sprinkler,rain)\": \"0.00198\", \"p(grass_wet|sprinkler,no_rain)\": \"0.288\", \"p(grass_wet|no_sprinkler,rain)\": \"0.1584\", \"p(grass_wet|no_sprinkler,no_rain)\": \"0\", \"p(no_grass_wet|sprinkler,rain)\": \"0.00002\", \"p(no_grass_wet|sprinkler,no_rain)\": \"0.032\", \"p(no_grass_wet|no_sprinkler,rain)\": \"0.0396\", \"p(no_grass_wet|no_sprinkler,no_rain)\": \"0.48\"}}\\n + <P1b>: We all recognise the value of, for example, legislating against incitement to racial hatred. #pro\\n  - <C1b>: Censorship such as legislation against incitement to racial hatred drives racists and others underground and thus entrenches and ghettoises that section of the community rather than drawing its members into open and rational debate. #con\\n + <P2>: Certain types of literature or visual image have been conclusively linked to crime. Excessive sex and violence in film and television has been shown (especially in studies in the US) to contribute to a tendency towards similar behaviour in spectators. There is no excuse for this and such images must be sacrificed, no matter what their artistic merit. #pro\\n  - <C2>: In fact, the link between sex and violence on screen and in real life is far from conclusive. To look at it from another angle, those individuals who _already have tendencies_ to violence are likely to watch violent `video nasties\\', just as those with a predilection for rape are likely to use pornography. The two are therefore connected but the individual\\'s personality is formed first. #con\\n   - <C3>: Trying whether a third generation will also work. /* plus adding a comment to ignore <hallo> */\\n   - [Thesis]\\n - <C1a>: Censorship is wrong in principle. However violently we may disagree with a person\\'s point of view or mode of expression, they must be free to express themselves in a free and civilized society.\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3S5fqk7BHFVm"
      },
      "outputs": [],
      "source": [
        "def parse_markdown_hierarchy(markdown_text):\n",
        "    \"\"\"Main function to parse markdown hierarchy into a DataFrame\"\"\"\n",
        "\n",
        "    # Remove comments\n",
        "    clean_text = remove_comments(markdown_text)\n",
        "\n",
        "    # Extract all titles with their descriptions and indentation levels\n",
        "    titles_info = extract_titles_info(clean_text)\n",
        "\n",
        "    # Establish parent-child relationships\n",
        "    titles_with_relations = establish_relationships(titles_info, clean_text)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = convert_to_dataframe(titles_with_relations)\n",
        "\n",
        "    # Add No_Parent and No_Children columns\n",
        "    df = add_no_parent_no_child_columns_to_df(df)\n",
        "\n",
        "    return df\n",
        "\n",
        "def remove_comments(markdown_text):\n",
        "    \"\"\"Remove comment blocks from markdown text\"\"\"\n",
        "    return re.sub(r'/\\*.*?\\*/', '', markdown_text, flags=re.DOTALL)\n",
        "\n",
        "def extract_titles_info(text):\n",
        "    \"\"\"Extract titles with their descriptions and indentation levels\"\"\"\n",
        "    lines = text.split('\\n')\n",
        "    titles_info = {}\n",
        "\n",
        "    for line in lines:\n",
        "        if not line.strip():\n",
        "            continue\n",
        "\n",
        "        title_match = re.search(r'[<\\[](.+?)[>\\]]', line)\n",
        "        if not title_match:\n",
        "            continue\n",
        "\n",
        "        title = title_match.group(1)\n",
        "\n",
        "        # Extract description and metadata\n",
        "        title_pattern_in_line = r'[<\\[]' + re.escape(title) + r'[>\\]]:'\n",
        "        description_match = re.search(title_pattern_in_line + r'\\s*(.*)', line)\n",
        "\n",
        "        if description_match:\n",
        "            full_text = description_match.group(1).strip()\n",
        "\n",
        "            # Check if description contains a \"{\" to not include metadata in description\n",
        "            if \"{\" in full_text:\n",
        "                # Split at the first \"{\"\n",
        "                split_index = full_text.find(\"{\")\n",
        "                description = full_text[:split_index].strip()\n",
        "                metadata = full_text[split_index:].strip()\n",
        "            else:\n",
        "                # Keep the entire description and no metadata\n",
        "                description = full_text\n",
        "                metadata = ''\n",
        "        else:\n",
        "            description = ''\n",
        "            metadata = ''  # Ensure metadata is initialized as empty string\n",
        "\n",
        "        indentation = 0\n",
        "        if '+' in line:\n",
        "            symbol_index = line.find('+')\n",
        "            # Count spaces before the '+' symbol\n",
        "            i = symbol_index - 1\n",
        "            while i >= 0 and line[i] == ' ':\n",
        "                indentation += 1\n",
        "                i -= 1\n",
        "        elif '-' in line:\n",
        "            symbol_index = line.find('-')\n",
        "            # Count spaces before the '-' symbol\n",
        "            i = symbol_index - 1\n",
        "            while i >= 0 and line[i] == ' ':\n",
        "                indentation += 1\n",
        "                i -= 1\n",
        "\n",
        "        # If neither symbol exists, indentation remains 0\n",
        "\n",
        "        if title in titles_info:\n",
        "            # Only update description if it's currently empty and we found a new one\n",
        "            if not titles_info[title]['description'] and description:\n",
        "                titles_info[title]['description'] = description\n",
        "\n",
        "            # Store all indentation levels for this title\n",
        "            titles_info[title]['indentation_levels'].append(indentation)\n",
        "\n",
        "            # Keep max indentation for backward compatibility\n",
        "            if indentation > titles_info[title]['indentation']:\n",
        "                titles_info[title]['indentation'] = indentation\n",
        "\n",
        "            # Do NOT update metadata here - keep the original metadata\n",
        "        else:\n",
        "            # First time seeing this title, create a new entry\n",
        "            titles_info[title] = {\n",
        "                'description': description,\n",
        "                'indentation': indentation,\n",
        "                'indentation_levels': [indentation],  # Initialize with first indentation level\n",
        "                'parents': [],\n",
        "                'children': [],\n",
        "                'line': None,\n",
        "                'line_numbers': [],  # Initialize an empty list for all occurrences\n",
        "                'metadata': metadata  # Set metadata explicitly from what we found\n",
        "            }\n",
        "\n",
        "    return titles_info\n",
        "\n",
        "def establish_relationships(titles_info, text):\n",
        "    \"\"\"Establish parent-child relationships between titles using the BayesDown indentation rules\"\"\"\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Dictionary to store line numbers for each title occurrence\n",
        "    title_occurrences = {}\n",
        "\n",
        "    # Record line number for each title (including multiple occurrences)\n",
        "    line_number = 0\n",
        "    for line in lines:\n",
        "        if not line.strip():\n",
        "            line_number += 1\n",
        "            continue\n",
        "\n",
        "        title_match = re.search(r'[<\\[](.+?)[>\\]]', line)\n",
        "        if not title_match:\n",
        "            line_number += 1\n",
        "            continue\n",
        "\n",
        "        title = title_match.group(1)\n",
        "\n",
        "        # Store all occurrences of each title with their line numbers\n",
        "        if title not in title_occurrences:\n",
        "            title_occurrences[title] = []\n",
        "        title_occurrences[title].append(line_number)\n",
        "\n",
        "        # Store all line numbers where this title appears\n",
        "        if 'line_numbers' not in titles_info[title]:\n",
        "            titles_info[title]['line_numbers'] = []\n",
        "        titles_info[title]['line_numbers'].append(line_number)\n",
        "\n",
        "        # For backward compatibility, keep the first occurrence in 'line'\n",
        "        if titles_info[title]['line'] is None:\n",
        "            titles_info[title]['line'] = line_number\n",
        "\n",
        "        line_number += 1\n",
        "\n",
        "    # Create an ordered list of all title occurrences with their line numbers\n",
        "    all_occurrences = []\n",
        "    for title, occurrences in title_occurrences.items():\n",
        "        for line_num in occurrences:\n",
        "            all_occurrences.append((title, line_num))\n",
        "\n",
        "    # Sort occurrences by line number\n",
        "    all_occurrences.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Get indentation for each occurrence\n",
        "    occurrence_indents = {}\n",
        "    for title, line_num in all_occurrences:\n",
        "        for line in lines[line_num:line_num+1]:  # Only check the current line\n",
        "            indent = 0\n",
        "            if '+' in line:\n",
        "                symbol_index = line.find('+')\n",
        "                # Count spaces before the '+' symbol\n",
        "                j = symbol_index - 1\n",
        "                while j >= 0 and line[j] == ' ':\n",
        "                    indent += 1\n",
        "                    j -= 1\n",
        "            elif '-' in line:\n",
        "                symbol_index = line.find('-')\n",
        "                # Count spaces before the '-' symbol\n",
        "                j = symbol_index - 1\n",
        "                while j >= 0 and line[j] == ' ':\n",
        "                    indent += 1\n",
        "                    j -= 1\n",
        "            occurrence_indents[(title, line_num)] = indent\n",
        "\n",
        "    # Process for finding parents (looking forward)\n",
        "    for i, (title, line_num) in enumerate(all_occurrences):\n",
        "        current_indent = occurrence_indents[(title, line_num)]\n",
        "\n",
        "        # Look ahead for potential parents that are exactly one indentation level higher\n",
        "        j = i + 1\n",
        "        while j < len(all_occurrences):\n",
        "            next_title, next_line = all_occurrences[j]\n",
        "            next_indent = occurrence_indents[(next_title, next_line)]\n",
        "\n",
        "            # If we find a title with same or less indentation, stop looking in this section\n",
        "            if next_indent <= current_indent:\n",
        "                break\n",
        "\n",
        "            # If this is a direct parent (exactly one more indentation) and not the same title\n",
        "            if next_indent == current_indent + 1 and next_title != title:\n",
        "                # More indented node is parent of less indented node\n",
        "                if next_title not in titles_info[title]['parents']:\n",
        "                    titles_info[title]['parents'].append(next_title)\n",
        "                if title not in titles_info[next_title]['children']:\n",
        "                    titles_info[next_title]['children'].append(title)\n",
        "\n",
        "            j += 1\n",
        "\n",
        "    # Process for finding children (looking backward)\n",
        "    for i, (title, line_num) in enumerate(all_occurrences):\n",
        "        current_indent = occurrence_indents[(title, line_num)]\n",
        "\n",
        "        # Skip titles with indentation 0 (they don't have children by looking backward)\n",
        "        if current_indent == 0:\n",
        "            continue\n",
        "\n",
        "        # Look for the immediately preceding title with one less indentation (immediate child)\n",
        "        j = i - 1\n",
        "        found_child = False\n",
        "\n",
        "        while j >= 0 and not found_child:\n",
        "            prev_title, prev_line = all_occurrences[j]\n",
        "            prev_indent = occurrence_indents[(prev_title, prev_line)]\n",
        "\n",
        "            # If the previous title has exactly one less indentation and is not the same title\n",
        "            if prev_indent == current_indent - 1 and prev_title != title:\n",
        "                # Current title is parent of previous title\n",
        "                if title not in titles_info[prev_title]['parents']:\n",
        "                    titles_info[prev_title]['parents'].append(title)\n",
        "                if prev_title not in titles_info[title]['children']:\n",
        "                    titles_info[title]['children'].append(prev_title)\n",
        "                found_child = True  # Only find one immediate child\n",
        "\n",
        "            # If we encounter a title with even less indentation, stop looking\n",
        "            if prev_indent < current_indent - 1:\n",
        "                break\n",
        "\n",
        "            j -= 1\n",
        "\n",
        "    return titles_info\n",
        "\n",
        "    return titles_info\n",
        "\n",
        "def convert_to_dataframe(titles_info):\n",
        "    \"\"\"Convert the titles information dictionary to a pandas DataFrame\"\"\"\n",
        "    df = pd.DataFrame(columns=['Title', 'Description', 'line', 'line_numbers', 'indentation',\n",
        "                               'indentation_levels', 'Parents', 'Children', 'instantiations',\n",
        "                               'priors', 'posteriors'])\n",
        "\n",
        "    for title, info in titles_info.items():\n",
        "        # Parse the metadata JSON string into a Python dictionary\n",
        "        if 'metadata' in info and info['metadata']:\n",
        "            try:\n",
        "                # Only try to parse if metadata is not empty\n",
        "                if info['metadata'].strip():\n",
        "                    jsonMetadata = json.loads(info['metadata'])\n",
        "\n",
        "                    # Create the row dictionary with basic fields\n",
        "                    row = {\n",
        "                        'Title': title,\n",
        "                        'Description': info.get('description', ''),\n",
        "                        'line': info.get('line',''),\n",
        "                        'line_numbers': info.get('line_numbers', []),\n",
        "                        'indentation': info.get('indentation',''),\n",
        "                        'indentation_levels': info.get('indentation_levels', []),\n",
        "                        'Parents': info.get('parents', []),\n",
        "                        'Children': info.get('children', []),\n",
        "                        # Extract specific metadata fields, defaulting to empty if not present\n",
        "                        'instantiations': jsonMetadata.get('instantiations', []),\n",
        "                        'priors': jsonMetadata.get('priors', {}),\n",
        "                        'posteriors': jsonMetadata.get('posteriors', {})\n",
        "                    }\n",
        "                else:\n",
        "                    # Empty metadata case\n",
        "                    row = {\n",
        "                        'Title': title,\n",
        "                        'Description': info.get('description', ''),\n",
        "                        'line': info.get('line',''),\n",
        "                        'line_numbers': info.get('line_numbers', []),\n",
        "                        'indentation': info.get('indentation',''),\n",
        "                        'indentation_levels': info.get('indentation_levels', []),\n",
        "                        'Parents': info.get('parents', []),\n",
        "                        'Children': info.get('children', []),\n",
        "                        'instantiations': [],\n",
        "                        'priors': {},\n",
        "                        'posteriors': {}\n",
        "                    }\n",
        "            except json.JSONDecodeError:\n",
        "                # Handle case where metadata isn't valid JSON\n",
        "                row = {\n",
        "                    'Title': title,\n",
        "                    'Description': info.get('description', ''),\n",
        "                    'line': info.get('line',''),\n",
        "                    'line_numbers': info.get('line_numbers', []),\n",
        "                    'indentation': info.get('indentation',''),\n",
        "                    'indentation_levels': info.get('indentation_levels', []),\n",
        "                    'Parents': info.get('parents', []),\n",
        "                    'Children': info.get('children', []),\n",
        "                    'instantiations': [],\n",
        "                    'priors': {},\n",
        "                    'posteriors': {}\n",
        "                }\n",
        "        else:\n",
        "            # Handle case where metadata field doesn't exist or is empty\n",
        "            row = {\n",
        "                'Title': title,\n",
        "                'Description': info.get('description', ''),\n",
        "                'line': info.get('line',''),\n",
        "                'line_numbers': info.get('line_numbers', []),\n",
        "                'indentation': info.get('indentation',''),\n",
        "                'indentation_levels': info.get('indentation_levels', []),\n",
        "                'Parents': info.get('parents', []),\n",
        "                'Children': info.get('children', []),\n",
        "                'instantiations': [],\n",
        "                'priors': {},\n",
        "                'posteriors': {}\n",
        "            }\n",
        "\n",
        "        # Add the row to the DataFrame\n",
        "        df.loc[len(df)] = row\n",
        "\n",
        "    return df\n",
        "\n",
        "def add_no_parent_no_child_columns_to_df(dataframe):\n",
        "    \"\"\"Add No_Parent and No_Children boolean columns to the DataFrame\"\"\"\n",
        "    no_parent = []\n",
        "    no_children = []\n",
        "\n",
        "    for _, row in dataframe.iterrows():\n",
        "        no_parent.append(not row['Parents'])\n",
        "        no_children.append(not row['Children'])\n",
        "\n",
        "    dataframe['No_Parent'] = no_parent\n",
        "    dataframe['No_Children'] = no_children\n",
        "\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hmoEC7JaHFVn",
        "outputId": "a48adae3-a6de-4d8e-f160-e837c53184ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Title                                        Description  line  \\\n",
              "0  Grass_Wet  Concentrated moisture on, between and around t...     3   \n",
              "1       Rain  Tears of angles crying high up in the skies hi...     4   \n",
              "2  Sprinkler  Activation of a centrifugal force based CO2 dr...     5   \n",
              "\n",
              "  line_numbers  indentation indentation_levels            Parents  \\\n",
              "0          [3]            0                [0]  [Rain, Sprinkler]   \n",
              "1       [4, 6]            2             [1, 2]                 []   \n",
              "2          [5]            1                [1]             [Rain]   \n",
              "\n",
              "                 Children                     instantiations  \\\n",
              "0                      []  [grass_wet_TRUE, grass_wet_FALSE]   \n",
              "1  [Grass_Wet, Sprinkler]            [rain_TRUE, rain_FALSE]   \n",
              "2             [Grass_Wet]  [sprinkler_TRUE, sprinkler_FALSE]   \n",
              "\n",
              "                                              priors  \\\n",
              "0  {'p(grass_wet_TRUE)': '0.322', 'p(grass_wet_FA...   \n",
              "1    {'p(rain_TRUE)': '0.2', 'p(rain_FALSE)': '0.8'}   \n",
              "2  {'p(sprinkler_TRUE)': '0.44838', 'p(sprinkler_...   \n",
              "\n",
              "                                          posteriors  No_Parent  No_Children  \n",
              "0  {'p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)':...      False         True  \n",
              "1                                                 {}       True        False  \n",
              "2  {'p(sprinkler_TRUE|rain_TRUE)': '0.01', 'p(spr...      False        False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da0b7aef-a8b2-4b2c-8a0c-6bdd30bb58f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>line</th>\n",
              "      <th>line_numbers</th>\n",
              "      <th>indentation</th>\n",
              "      <th>indentation_levels</th>\n",
              "      <th>Parents</th>\n",
              "      <th>Children</th>\n",
              "      <th>instantiations</th>\n",
              "      <th>priors</th>\n",
              "      <th>posteriors</th>\n",
              "      <th>No_Parent</th>\n",
              "      <th>No_Children</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Grass_Wet</td>\n",
              "      <td>Concentrated moisture on, between and around t...</td>\n",
              "      <td>3</td>\n",
              "      <td>[3]</td>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[Rain, Sprinkler]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[grass_wet_TRUE, grass_wet_FALSE]</td>\n",
              "      <td>{'p(grass_wet_TRUE)': '0.322', 'p(grass_wet_FA...</td>\n",
              "      <td>{'p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)':...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Tears of angles crying high up in the skies hi...</td>\n",
              "      <td>4</td>\n",
              "      <td>[4, 6]</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Grass_Wet, Sprinkler]</td>\n",
              "      <td>[rain_TRUE, rain_FALSE]</td>\n",
              "      <td>{'p(rain_TRUE)': '0.2', 'p(rain_FALSE)': '0.8'}</td>\n",
              "      <td>{}</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sprinkler</td>\n",
              "      <td>Activation of a centrifugal force based CO2 dr...</td>\n",
              "      <td>5</td>\n",
              "      <td>[5]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[Rain]</td>\n",
              "      <td>[Grass_Wet]</td>\n",
              "      <td>[sprinkler_TRUE, sprinkler_FALSE]</td>\n",
              "      <td>{'p(sprinkler_TRUE)': '0.44838', 'p(sprinkler_...</td>\n",
              "      <td>{'p(sprinkler_TRUE|rain_TRUE)': '0.01', 'p(spr...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da0b7aef-a8b2-4b2c-8a0c-6bdd30bb58f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da0b7aef-a8b2-4b2c-8a0c-6bdd30bb58f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da0b7aef-a8b2-4b2c-8a0c-6bdd30bb58f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-25af8679-3d33-4959-bd66-7934d2668cb8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25af8679-3d33-4959-bd66-7934d2668cb8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-25af8679-3d33-4959-bd66-7934d2668cb8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_07af53f5-1bc9-45bb-84ec-2b26acdd5caa\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_07af53f5-1bc9-45bb-84ec-2b26acdd5caa button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Grass_Wet\",\n          \"Rain\",\n          \"Sprinkler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Concentrated moisture on, between and around the blades of grass.\",\n          \"Tears of angles crying high up in the skies hitting the ground.\",\n          \"Activation of a centrifugal force based CO2 droplet distribution system.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_numbers\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indentation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indentation_levels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parents\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Children\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instantiations\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"priors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"posteriors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_Parent\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_Children\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "result_df = parse_markdown_hierarchy(md_content_ex_rain)\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pwMzzPxfHFVn",
        "outputId": "8623e966-7956-4b0d-f7e3-a8cdb291138c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'md_content_easy_ex_B_CG' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-14e900d0e136>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_df_CG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_markdown_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_content_easy_ex_B_CG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult_df_CG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'md_content_easy_ex_B_CG' is not defined"
          ]
        }
      ],
      "source": [
        "result_df_CG = parse_markdown_hierarchy(md_content_easy_ex_B_CG)\n",
        "result_df_CG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcXf3fZ8dahj"
      },
      "source": [
        "### 3.3 Data-Post-Processing\n",
        "Add rows to data frame that can be calculated from the extracted rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0BjD1J1dahj"
      },
      "outputs": [],
      "source": [
        "# here we add all the rows that we have to calculate (joint probability..., maybe in several rounds (e.g. first add conditional proability, then use this column to calc joint probability...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTwPO_J-dahj"
      },
      "source": [
        "### 3.4 Download and save finished data frame as .csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5rJEacladahj"
      },
      "outputs": [],
      "source": [
        "result_df.to_csv('extracted_data.csv', index=False) # save dataframe in environment as .csv file\n",
        "# Attention: if the new or updated .csv file is required later, it needs to be pushed to the GitRepository!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGoZ9gH55271"
      },
      "source": [
        "# 4.0 Analysis & Inference: Practical Software Tools ()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 Core Functions with Imports"
      ],
      "metadata": {
        "id": "Y1EZhHALq6kA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt 1"
      ],
      "metadata": {
        "id": "6H7SpKDbrBGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvis.network import Network\n",
        "import networkx as nx\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import base64\n",
        "import colorsys\n",
        "import json\n",
        "\n",
        "def create_bayesian_network_with_probabilities(df):\n",
        "    \"\"\"\n",
        "    Create an interactive Bayesian network visualization with enhanced probability visualization\n",
        "    and node classification based on network structure.\n",
        "    \"\"\"\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes with proper attributes\n",
        "    for idx, row in df.iterrows():\n",
        "        title = row['Title']\n",
        "        description = row['Description']\n",
        "\n",
        "        # Process probability information\n",
        "        priors = get_priors(row)\n",
        "        instantiations = get_instantiations(row)\n",
        "\n",
        "        # Add node with base information\n",
        "        G.add_node(\n",
        "            title,\n",
        "            description=description,\n",
        "            priors=priors,\n",
        "            instantiations=instantiations,\n",
        "            posteriors=get_posteriors(row)\n",
        "        )\n",
        "\n",
        "    # Add edges\n",
        "    for idx, row in df.iterrows():\n",
        "        child = row['Title']\n",
        "        parents = get_parents(row)\n",
        "\n",
        "        # Add edges from each parent to this child\n",
        "        for parent in parents:\n",
        "            if parent in G.nodes():\n",
        "                G.add_edge(parent, child)\n",
        "\n",
        "    # Classify nodes based on network structure\n",
        "    classify_nodes(G)\n",
        "\n",
        "    # Create network visualization\n",
        "    net = Network(notebook=True, directed=True, cdn_resources=\"in_line\", height=\"600px\", width=\"100%\")\n",
        "\n",
        "    # Configure physics for better layout\n",
        "    net.force_atlas_2based(gravity=-50, spring_length=100, spring_strength=0.02)\n",
        "    net.show_buttons(filter_=['physics'])\n",
        "\n",
        "    # Add the graph to the network\n",
        "    net.from_nx(G)\n",
        "\n",
        "    # Enhance node appearance with probability information and classification\n",
        "    for node in net.nodes:\n",
        "        node_id = node['id']\n",
        "        node_data = G.nodes[node_id]\n",
        "\n",
        "        # Get node type and set border color\n",
        "        node_type = node_data.get('node_type', 'unknown')\n",
        "        border_color = get_border_color(node_type)\n",
        "\n",
        "        # Get probability information\n",
        "        priors = node_data.get('priors', {})\n",
        "        true_prob = priors.get('true_prob', 0.5) if priors else 0.5\n",
        "\n",
        "        # Get proper state names\n",
        "        instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "        true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "        false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "        # Create background color based on probability\n",
        "        background_color = get_probability_color(priors)\n",
        "\n",
        "        # Create tooltip with probability information\n",
        "        tooltip = create_tooltip(node_id, node_data)\n",
        "\n",
        "        # Create a simpler node label with probability\n",
        "        simple_label = f\"{node_id}\\np={true_prob:.2f}\"\n",
        "\n",
        "        # Store expanded content as a node attribute for use in click handler\n",
        "        node_data['expanded_content'] = create_expanded_content(node_id, node_data)\n",
        "\n",
        "        # Set node attributes\n",
        "        node['title'] = tooltip  # Tooltip HTML\n",
        "        node['label'] = simple_label  # Simple text label\n",
        "        node['shape'] = 'box'\n",
        "        node['color'] = {\n",
        "            'background': background_color,\n",
        "            'border': border_color,\n",
        "            'highlight': {\n",
        "                'background': background_color,\n",
        "                'border': border_color\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # Set up the click handler with proper data\n",
        "    setup_data = {\n",
        "        'nodes_data': {node_id: {\n",
        "            'expanded_content': json.dumps(G.nodes[node_id].get('expanded_content', '')),\n",
        "            'description': G.nodes[node_id].get('description', ''),\n",
        "            'priors': G.nodes[node_id].get('priors', {}),\n",
        "            'posteriors': G.nodes[node_id].get('posteriors', {})\n",
        "        } for node_id in G.nodes()}\n",
        "    }\n",
        "\n",
        "    # Add custom click handling JavaScript\n",
        "    click_js = \"\"\"\n",
        "    // Store node data for click handling\n",
        "    var nodesData = %s;\n",
        "\n",
        "    // Add event listener for node clicks\n",
        "    network.on(\"click\", function(params) {\n",
        "        if (params.nodes.length > 0) {\n",
        "            var nodeId = params.nodes[0];\n",
        "            var nodeInfo = nodesData[nodeId];\n",
        "\n",
        "            if (nodeInfo) {\n",
        "                // Create a modal popup for expanded content\n",
        "                var modal = document.createElement('div');\n",
        "                modal.style.position = 'fixed';\n",
        "                modal.style.left = '50%%';\n",
        "                modal.style.top = '50%%';\n",
        "                modal.style.transform = 'translate(-50%%, -50%%)';\n",
        "                modal.style.backgroundColor = 'white';\n",
        "                modal.style.padding = '20px';\n",
        "                modal.style.borderRadius = '5px';\n",
        "                modal.style.boxShadow = '0 0 10px rgba(0,0,0,0.5)';\n",
        "                modal.style.zIndex = '1000';\n",
        "                modal.style.maxWidth = '80%%';\n",
        "                modal.style.maxHeight = '80%%';\n",
        "                modal.style.overflow = 'auto';\n",
        "\n",
        "                // Add expanded content\n",
        "                modal.innerHTML = nodeInfo.expanded_content || 'No detailed information available';\n",
        "\n",
        "                // Add close button\n",
        "                var closeBtn = document.createElement('button');\n",
        "                closeBtn.innerHTML = 'Close';\n",
        "                closeBtn.style.marginTop = '10px';\n",
        "                closeBtn.style.padding = '5px 10px';\n",
        "                closeBtn.style.cursor = 'pointer';\n",
        "                closeBtn.onclick = function() {\n",
        "                    document.body.removeChild(modal);\n",
        "                };\n",
        "                modal.appendChild(closeBtn);\n",
        "\n",
        "                // Add modal to body\n",
        "                document.body.appendChild(modal);\n",
        "            }\n",
        "        }\n",
        "    });\n",
        "    \"\"\" % json.dumps(setup_data['nodes_data'])\n",
        "\n",
        "    # Save the graph to HTML\n",
        "    html_file = \"bayesian_network.html\"\n",
        "    net.save_graph(html_file)\n",
        "\n",
        "    # Inject custom click handling into HTML\n",
        "    try:\n",
        "        with open(html_file, \"r\") as f:\n",
        "            html_content = f.read()\n",
        "\n",
        "        # Insert click handling script before the closing body tag\n",
        "        html_content = html_content.replace('</body>', f'<script>{click_js}</script></body>')\n",
        "\n",
        "        # Write back the modified HTML\n",
        "        with open(html_file, \"w\") as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        return HTML(html_content)\n",
        "    except Exception as e:\n",
        "        return HTML(f\"<p>Error rendering HTML: {str(e)}</p><p>The network visualization has been saved to '{html_file}'</p>\")\n",
        "\n",
        "def classify_nodes(G):\n",
        "    \"\"\"\n",
        "    Classify nodes as parent, child, or leaf based on network structure\n",
        "    \"\"\"\n",
        "    for node in G.nodes():\n",
        "        predecessors = list(G.predecessors(node))\n",
        "        successors = list(G.successors(node))\n",
        "\n",
        "        if not predecessors:  # No parents\n",
        "            if successors:  # Has children\n",
        "                G.nodes[node]['node_type'] = 'parent'\n",
        "            else:  # No children either\n",
        "                G.nodes[node]['node_type'] = 'isolated'\n",
        "        else:  # Has parents\n",
        "            if not successors:  # No children\n",
        "                G.nodes[node]['node_type'] = 'leaf'\n",
        "            else:  # Has both parents and children\n",
        "                G.nodes[node]['node_type'] = 'child'\n",
        "\n",
        "def get_border_color(node_type):\n",
        "    \"\"\"\n",
        "    Return border color based on node type\n",
        "    \"\"\"\n",
        "    if node_type == 'parent':\n",
        "        return '#0000FF'  # Blue\n",
        "    elif node_type == 'child':\n",
        "        return '#800080'  # Purple\n",
        "    elif node_type == 'leaf':\n",
        "        return '#FF00FF'  # Magenta\n",
        "    else:\n",
        "        return '#000000'  # Default black\n",
        "\n",
        "def get_probability_color(priors):\n",
        "    \"\"\"\n",
        "    Create background color based on probability (red to green gradient)\n",
        "    \"\"\"\n",
        "    # Default to neutral color if no probability\n",
        "    if not priors or 'true_prob' not in priors:\n",
        "        return '#F8F8F8'  # Light grey\n",
        "\n",
        "    # Get probability value\n",
        "    prob = priors['true_prob']\n",
        "\n",
        "    # Create color gradient from red (0.0) to green (1.0)\n",
        "    hue = 120 * prob  # 0 = red, 120 = green (in HSL color space)\n",
        "    saturation = 0.75\n",
        "    lightness = 0.8  # Lighter color for better text visibility\n",
        "\n",
        "    # Convert HSL to RGB\n",
        "    r, g, b = colorsys.hls_to_rgb(hue/360, lightness, saturation)\n",
        "\n",
        "    # Convert to hex format\n",
        "    hex_color = \"#{:02x}{:02x}{:02x}\".format(int(r*255), int(g*255), int(b*255))\n",
        "\n",
        "    return hex_color\n",
        "\n",
        "def create_tooltip(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create rich HTML tooltip with probability information\n",
        "    Uses simplified HTML that works well in tooltips\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Start building the HTML tooltip\n",
        "    html = f\"\"\"\n",
        "    <div style='max-width:350px; padding:10px; background-color:#f8f9fa; border-radius:5px; font-family:Arial, sans-serif;'>\n",
        "        <h3 style='margin-top:0; color:#202124;'>{node_id}</h3>\n",
        "        <p style='font-style:italic;'>{description}</p>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add probability information if available\n",
        "    if priors and 'true_prob' in priors:\n",
        "        true_prob = priors['true_prob']\n",
        "        false_prob = 1.0 - true_prob\n",
        "\n",
        "        # Get proper state names\n",
        "        true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "        false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <div style='margin-top:10px; background-color:#fff; padding:8px; border-radius:4px; border:1px solid #ddd;'>\n",
        "            <h4 style='margin-top:0; font-size:14px;'>Probabilities:</h4>\n",
        "            <div>{true_state}: <b>{true_prob:.3f}</b></div>\n",
        "            <div>{false_state}: <b>{false_prob:.3f}</b></div>\n",
        "            <div style='width:100%; height:20px; margin-top:5px; border:1px solid #ccc;'>\n",
        "                <div style='float:left; width:{true_prob*100}%; height:100%; background-color:rgba(0,200,0,0.5); border-right:2px solid green;'></div>\n",
        "                <div style='float:left; width:{false_prob*100}%; height:100%; background-color:rgba(255,0,0,0.5);'></div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Add click instruction\n",
        "    html += \"\"\"\n",
        "    <div style='margin-top:10px; font-size:12px; text-align:center; color:#666;'>\n",
        "        Click for detailed information\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Close the main div\n",
        "    html += \"</div>\"\n",
        "\n",
        "    return html\n",
        "\n",
        "def create_expanded_content(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create expanded content shown when a node is clicked\n",
        "    This is stored as a string and converted to HTML in the click handler\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    posteriors = node_data.get('posteriors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Get probability values\n",
        "    true_prob = priors.get('true_prob', 0.5) if priors else 0.5\n",
        "    false_prob = 1.0 - true_prob\n",
        "\n",
        "    # Get proper state names\n",
        "    true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "    false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "    # Start building HTML content\n",
        "    html = f\"\"\"\n",
        "    <div style=\"max-width:600px; padding:20px;\">\n",
        "        <h2 style=\"margin-top:0;\">{node_id}</h2>\n",
        "        <p style=\"font-style:italic;\">{description}</p>\n",
        "\n",
        "        <div style=\"margin-top:20px;\">\n",
        "            <h3>Prior Probabilities</h3>\n",
        "            <table style=\"width:100%; border-collapse:collapse;\">\n",
        "                <tr style=\"background-color:#f0f0f0;\">\n",
        "                    <th style=\"padding:8px; border:1px solid #ddd; text-align:left;\">State</th>\n",
        "                    <th style=\"padding:8px; border:1px solid #ddd; text-align:right;\">Probability</th>\n",
        "                    <th style=\"padding:8px; border:1px solid #ddd;\">Visualization</th>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">{true_state}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd; text-align:right;\">{true_prob:.3f}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">\n",
        "                        <div style=\"width:100%; height:20px; background-color:#f0f0f0;\">\n",
        "                            <div style=\"width:{true_prob*100}%; height:100%; background-color:rgba(0,200,0,0.5);\"></div>\n",
        "                        </div>\n",
        "                    </td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">{false_state}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd; text-align:right;\">{false_prob:.3f}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">\n",
        "                        <div style=\"width:100%; height:20px; background-color:#f0f0f0;\">\n",
        "                            <div style=\"width:{false_prob*100}%; height:100%; background-color:rgba(255,0,0,0.5);\"></div>\n",
        "                        </div>\n",
        "                    </td>\n",
        "                </tr>\n",
        "            </table>\n",
        "        </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add conditional probabilities if available\n",
        "    if posteriors and len(posteriors) > 0:\n",
        "        html += \"\"\"\n",
        "        <div style=\"margin-top:20px;\">\n",
        "            <h3>Conditional Probabilities</h3>\n",
        "            <table style=\"width:100%; border-collapse:collapse;\">\n",
        "                <tr style=\"background-color:#f0f0f0;\">\n",
        "                    <th style=\"padding:8px; border:1px solid #ddd; text-align:left;\">Condition</th>\n",
        "                    <th style=\"padding:8px; border:1px solid #ddd; text-align:right;\">Value</th>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        # Add each conditional probability\n",
        "        for key, value in posteriors.items():\n",
        "            html += f\"\"\"\n",
        "            <tr>\n",
        "                <td style=\"padding:8px; border:1px solid #ddd;\">{key}</td>\n",
        "                <td style=\"padding:8px; border:1px solid #ddd; text-align:right;\">{value}</td>\n",
        "            </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        html += \"\"\"\n",
        "            </table>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Close the main container\n",
        "    html += \"\"\"\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    return html"
      ],
      "metadata": {
        "id": "RRZCQj7E5qIc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt 2"
      ],
      "metadata": {
        "id": "zHW_Vl-ErHaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import colorsys\n",
        "from pyvis.network import Network\n",
        "import networkx as nx\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "import json\n",
        "import re\n",
        "\n",
        "def create_bayesian_network_with_probabilities(df):\n",
        "    \"\"\"\n",
        "    Create an interactive Bayesian network visualization with enhanced probability visualization\n",
        "    and node classification based on network structure.\n",
        "    \"\"\"\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes with proper attributes\n",
        "    for idx, row in df.iterrows():\n",
        "        title = row['Title']\n",
        "        description = row['Description']\n",
        "\n",
        "        # Process probability information\n",
        "        priors = get_priors(row)\n",
        "        instantiations = get_instantiations(row)\n",
        "\n",
        "        # Add node with base information\n",
        "        G.add_node(\n",
        "            title,\n",
        "            description=description,\n",
        "            priors=priors,\n",
        "            instantiations=instantiations,\n",
        "            posteriors=get_posteriors(row)\n",
        "        )\n",
        "\n",
        "    # Add edges\n",
        "    for idx, row in df.iterrows():\n",
        "        child = row['Title']\n",
        "        parents = get_parents(row)\n",
        "\n",
        "        # Add edges from each parent to this child\n",
        "        for parent in parents:\n",
        "            if parent in G.nodes():\n",
        "                G.add_edge(parent, child)\n",
        "\n",
        "    # Classify nodes based on network structure\n",
        "    classify_nodes(G)\n",
        "\n",
        "    # Create network visualization\n",
        "    net = Network(notebook=True, directed=True, cdn_resources=\"in_line\", height=\"600px\", width=\"100%\")\n",
        "\n",
        "    # Configure physics for better layout\n",
        "    net.force_atlas_2based(gravity=-50, spring_length=100, spring_strength=0.02)\n",
        "    net.show_buttons(filter_=['physics'])\n",
        "\n",
        "    # Add the graph to the network\n",
        "    net.from_nx(G)\n",
        "\n",
        "    # Create store for expanded content to be passed to JavaScript\n",
        "    nodes_data_js = {}\n",
        "\n",
        "    # Enhance node appearance with probability information and classification\n",
        "    for node in net.nodes:\n",
        "        node_id = node['id']\n",
        "        node_data = G.nodes[node_id]\n",
        "\n",
        "        # Get node type and set border color\n",
        "        node_type = node_data.get('node_type', 'unknown')\n",
        "        border_color = get_border_color(node_type)\n",
        "\n",
        "        # Get probability and set background color\n",
        "        prob_color = get_probability_color(node_data.get('priors', {}))\n",
        "\n",
        "        # Create tooltip with probability information\n",
        "        tooltip = create_tooltip(node_id, node_data)\n",
        "\n",
        "        # Create expanded content with detailed probability information\n",
        "        expanded_content = create_expanded_content(node_id, node_data)\n",
        "\n",
        "        # Store expanded content for JavaScript access\n",
        "        nodes_data_js[node_id] = {\n",
        "            \"expanded_content\": json.dumps(expanded_content)\n",
        "        }\n",
        "\n",
        "        # Create the node label with probability visualization\n",
        "        node_label = create_node_label(node_id, node_data)\n",
        "\n",
        "        # Set node attributes\n",
        "        node['title'] = tooltip  # Tooltip HTML\n",
        "        node['label'] = node_label  # Node label HTML\n",
        "        node['shape'] = 'box'\n",
        "        node['color'] = {\n",
        "            'background': prob_color,\n",
        "            'border': border_color,\n",
        "            'highlight': {\n",
        "                'background': prob_color,\n",
        "                'border': border_color\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # Save and read the HTML content\n",
        "    html_file = \"bayesian_network.html\"\n",
        "    net.save_graph(html_file)\n",
        "\n",
        "    # Inject custom js data and click handling into HTML\n",
        "    try:\n",
        "        with open(html_file, \"r\") as f:\n",
        "            html_content = f.read()\n",
        "\n",
        "        # Insert node data for JavaScript\n",
        "        nodes_data_js_str = json.dumps(nodes_data_js)\n",
        "\n",
        "        # Create JavaScript for modal handling\n",
        "        modal_js = f\"\"\"\n",
        "        // Store node data for click handling\n",
        "        var nodesData = {nodes_data_js_str};\n",
        "\n",
        "        // Add event listener for node clicks\n",
        "        network.on(\"click\", function(params) {{\n",
        "            if (params.nodes.length > 0) {{\n",
        "                var nodeId = params.nodes[0];\n",
        "                var nodeInfo = nodesData[nodeId];\n",
        "\n",
        "                if (nodeInfo) {{\n",
        "                    // Create a modal popup for expanded content\n",
        "                    var modal = document.createElement('div');\n",
        "                    modal.style.position = 'fixed';\n",
        "                    modal.style.left = '50%';\n",
        "                    modal.style.top = '50%';\n",
        "                    modal.style.transform = 'translate(-50%, -50%)';\n",
        "                    modal.style.backgroundColor = 'white';\n",
        "                    modal.style.padding = '20px';\n",
        "                    modal.style.borderRadius = '5px';\n",
        "                    modal.style.boxShadow = '0 0 10px rgba(0,0,0,0.5)';\n",
        "                    modal.style.zIndex = '1000';\n",
        "                    modal.style.maxWidth = '80%';\n",
        "                    modal.style.maxHeight = '80%';\n",
        "                    modal.style.overflow = 'auto';\n",
        "\n",
        "                    // Add expanded content - parse from JSON to prevent escaping issues\n",
        "                    modal.innerHTML = JSON.parse(nodeInfo.expanded_content) || 'No detailed information available';\n",
        "\n",
        "                    // Add close button\n",
        "                    var closeBtn = document.createElement('button');\n",
        "                    closeBtn.innerHTML = 'Close';\n",
        "                    closeBtn.style.marginTop = '10px';\n",
        "                    closeBtn.style.padding = '5px 10px';\n",
        "                    closeBtn.style.cursor = 'pointer';\n",
        "                    closeBtn.onclick = function() {{\n",
        "                        document.body.removeChild(modal);\n",
        "                    }};\n",
        "                    modal.appendChild(closeBtn);\n",
        "\n",
        "                    // Add modal to body\n",
        "                    document.body.appendChild(modal);\n",
        "                }}\n",
        "            }}\n",
        "        }});\n",
        "        \"\"\"\n",
        "\n",
        "        # Insert modal JS after the network instantiation\n",
        "        html_content = html_content.replace('</script></body>', f'</script><script>{modal_js}</script></body>')\n",
        "\n",
        "        # Write back the modified HTML\n",
        "        with open(html_file, \"w\") as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        return HTML(html_content)\n",
        "    except Exception as e:\n",
        "        return HTML(f\"<p>Error rendering HTML: {str(e)}</p><p>The network visualization has been saved to '{html_file}'</p>\")\n",
        "\n",
        "def classify_nodes(G):\n",
        "    \"\"\"\n",
        "    Classify nodes as parent, child, or leaf based on network structure\n",
        "    \"\"\"\n",
        "    for node in G.nodes():\n",
        "        predecessors = list(G.predecessors(node))\n",
        "        successors = list(G.successors(node))\n",
        "\n",
        "        if not predecessors:  # No parents\n",
        "            if successors:  # Has children\n",
        "                G.nodes[node]['node_type'] = 'parent'\n",
        "            else:  # No children either\n",
        "                G.nodes[node]['node_type'] = 'isolated'\n",
        "        else:  # Has parents\n",
        "            if not successors:  # No children\n",
        "                G.nodes[node]['node_type'] = 'leaf'\n",
        "            else:  # Has both parents and children\n",
        "                G.nodes[node]['node_type'] = 'child'\n",
        "\n",
        "def get_border_color(node_type):\n",
        "    \"\"\"\n",
        "    Return border color based on node type\n",
        "    \"\"\"\n",
        "    if node_type == 'parent':\n",
        "        return '#0000FF'  # Blue\n",
        "    elif node_type == 'child':\n",
        "        return '#800080'  # Purple\n",
        "    elif node_type == 'leaf':\n",
        "        return '#FF00FF'  # Magenta\n",
        "    else:\n",
        "        return '#000000'  # Default black\n",
        "\n",
        "def get_probability_color(priors):\n",
        "    \"\"\"\n",
        "    Create background color based on probability (red to green gradient)\n",
        "    \"\"\"\n",
        "    # Default to neutral color if no probability\n",
        "    if not priors or 'true_prob' not in priors:\n",
        "        return '#F8F8F8'  # Light grey\n",
        "\n",
        "    # Get probability value\n",
        "    prob = priors['true_prob']\n",
        "\n",
        "    # Create color gradient from red (0.0) to green (1.0)\n",
        "    # Using HSL for better visual gradient\n",
        "    hue = 120 * prob  # 0 = red, 120 = green (in HSL color space)\n",
        "    saturation = 0.9  # Increased saturation for more vibrant colors\n",
        "    lightness = 0.75  # Slightly lighter for better text visibility\n",
        "\n",
        "    # Convert HSL to RGB\n",
        "    r, g, b = colorsys.hls_to_rgb(hue/360, lightness, saturation)\n",
        "\n",
        "    # Convert to hex format\n",
        "    hex_color = \"#{:02x}{:02x}{:02x}\".format(int(r*255), int(g*255), int(b*255))\n",
        "\n",
        "    return hex_color\n",
        "\n",
        "def create_probability_bar(true_prob, false_prob, height=\"15px\", show_values=True, value_prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Creates a reusable HTML bar to visualize probability distribution\n",
        "    \"\"\"\n",
        "    true_label = f\"{value_prefix}{true_prob:.3f}\" if show_values else \"\"\n",
        "    false_label = f\"{value_prefix}{false_prob:.3f}\" if show_values else \"\"\n",
        "\n",
        "    html = f\"\"\"\n",
        "    <div style=\"width:100%; height:{height}; display:flex; border:1px solid #ccc; overflow:hidden; border-radius:3px; margin-top:3px; margin-bottom:3px;\">\n",
        "        <div style=\"flex-basis:{true_prob*100}%; background:linear-gradient(to bottom, rgba(0,180,0,0.9), rgba(0,140,0,0.7)); border-right:2px solid #008800; display:flex; align-items:center; justify-content:center; overflow:hidden; min-width:{2 if true_prob > 0 else 0}px;\">\n",
        "            <span style=\"font-size:10px; color:white; text-shadow:0px 0px 2px #000;\">{true_label}</span>\n",
        "        </div>\n",
        "        <div style=\"flex-basis:{false_prob*100}%; background:linear-gradient(to bottom, rgba(220,0,0,0.9), rgba(180,0,0,0.7)); border-left:2px solid #880000; display:flex; align-items:center; justify-content:center; overflow:hidden; min-width:{2 if false_prob > 0 else 0}px;\">\n",
        "            <span style=\"font-size:10px; color:white; text-shadow:0px 0px 2px #000;\">{false_label}</span>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "def create_node_label(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create HTML label content for node with probability visualization\n",
        "    \"\"\"\n",
        "    priors = node_data.get('priors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # If no probability information, just return the node ID\n",
        "    if not priors or 'true_prob' not in priors:\n",
        "        return node_id\n",
        "\n",
        "    # Get probabilities\n",
        "    true_prob = priors.get('true_prob', 0.5)\n",
        "    false_prob = 1.0 - true_prob\n",
        "\n",
        "    # Get proper state names\n",
        "    true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "    false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "    # Create probability visualization bar\n",
        "    prob_bar = create_probability_bar(true_prob, false_prob, \"10px\", False)\n",
        "\n",
        "    # Create HTML for the node label with probability box\n",
        "    html = f\"\"\"\n",
        "    <div style=\"text-align:center; font-weight:bold;\">{node_id}</div>\n",
        "    <div style=\"margin-top:4px; display:flex; flex-direction:column; align-items:center;\">\n",
        "        <div style=\"font-size:10px;\">p={true_prob:.2f}</div>\n",
        "        {prob_bar}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    return html\n",
        "\n",
        "def create_expanded_content(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create expanded content shown when a node is clicked\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    posteriors = node_data.get('posteriors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Get proper state names\n",
        "    true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "    false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "    # Extract probabilities\n",
        "    true_prob = priors.get('true_prob', 0.5)\n",
        "    false_prob = 1.0 - true_prob\n",
        "\n",
        "    # Create unconditional probability visualization\n",
        "    prob_bar = create_probability_bar(true_prob, false_prob, \"20px\", True)\n",
        "\n",
        "    # Basic info section\n",
        "    html = f\"\"\"\n",
        "    <div style=\"max-width:500px; padding:15px; text-align:left; font-family:Arial, sans-serif;\">\n",
        "        <div style=\"font-weight:bold; font-size:18px; margin-bottom:8px; color:#333;\">{node_id}</div>\n",
        "        <div style=\"font-style:italic; margin:8px 0; font-size:14px; color:#555;\">{description}</div>\n",
        "\n",
        "        <div style=\"margin-top:15px; padding:10px; border:1px solid #ddd; border-radius:4px; background-color:#f9f9f9;\">\n",
        "            <div style=\"font-weight:bold; font-size:16px; margin-bottom:8px; color:#333;\">Prior Probabilities</div>\n",
        "            <div style=\"display:flex; justify-content:space-between; margin-bottom:5px;\">\n",
        "                <div style=\"font-size:12px;\">{true_state}: {true_prob:.3f}</div>\n",
        "                <div style=\"font-size:12px;\">{false_state}: {false_prob:.3f}</div>\n",
        "            </div>\n",
        "            {prob_bar}\n",
        "        </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add conditional probability table if available\n",
        "    if posteriors:\n",
        "        html += \"\"\"\n",
        "        <div style=\"margin-top:15px; padding:10px; border:1px solid #ddd; border-radius:4px; background-color:#f9f9f9;\">\n",
        "            <div style=\"font-weight:bold; font-size:16px; margin-bottom:8px; color:#333;\">Conditional Probabilities</div>\n",
        "            <table style=\"width:100%; border-collapse:collapse; font-size:13px;\">\n",
        "                <tr style=\"background-color:#eee;\">\n",
        "                    <th style=\"padding:8px; text-align:left; border:1px solid #ddd;\">Condition</th>\n",
        "                    <th style=\"padding:8px; text-align:center; border:1px solid #ddd; width:100px;\">Probability</th>\n",
        "                    <th style=\"padding:8px; text-align:center; border:1px solid #ddd;\">Visualization</th>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        # Sort posteriors to group by similar conditions\n",
        "        posterior_items = list(posteriors.items())\n",
        "        posterior_items.sort(key=lambda x: x[0])\n",
        "\n",
        "        # Add rows for conditional probabilities\n",
        "        for key, value in posterior_items:\n",
        "            try:\n",
        "                # Try to parse probability value\n",
        "                prob_value = float(value)\n",
        "                inv_prob = 1.0 - prob_value\n",
        "\n",
        "                # Create probability visualization bar\n",
        "                bar_html = create_probability_bar(prob_value, inv_prob, \"15px\", False)\n",
        "\n",
        "                # Add row with probability visualization\n",
        "                html += f\"\"\"\n",
        "                <tr>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">{key}</td>\n",
        "                    <td style=\"padding:8px; text-align:center; border:1px solid #ddd;\">{prob_value:.3f}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">\n",
        "                        {bar_html}\n",
        "                    </td>\n",
        "                </tr>\n",
        "                \"\"\"\n",
        "            except:\n",
        "                # Fallback for non-numeric values\n",
        "                html += f\"\"\"\n",
        "                <tr>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">{key}</td>\n",
        "                    <td style=\"padding:8px; text-align:center; border:1px solid #ddd;\" colspan=\"2\">{value}</td>\n",
        "                </tr>\n",
        "                \"\"\"\n",
        "\n",
        "        html += \"\"\"\n",
        "            </table>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    html += \"</div>\"\n",
        "\n",
        "    return html\n",
        "\n",
        "def create_tooltip(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create rich HTML tooltip with probability information and visualizations\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Start building the HTML tooltip\n",
        "    html = f\"\"\"\n",
        "    <div style='max-width:350px; padding:10px; background-color:#f8f9fa; border-radius:5px; font-family:Arial, sans-serif;'>\n",
        "        <h3 style='margin-top:0; color:#202124;'>{node_id}</h3>\n",
        "        <p style='font-style:italic;'>{description}</p>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add prior probabilities section with visualization\n",
        "    if priors and 'true_prob' in priors:\n",
        "        true_prob = priors['true_prob']\n",
        "        false_prob = 1.0 - true_prob\n",
        "\n",
        "        # Get proper state names\n",
        "        true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "        false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "        # Create probability visualization bar\n",
        "        prob_bar = create_probability_bar(true_prob, false_prob, \"20px\", True, \"p=\")\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <div style='margin-top:10px; background-color:#fff; padding:8px; border-radius:4px; border:1px solid #ddd;'>\n",
        "            <h4 style='margin-top:0; font-size:14px;'>Prior Probabilities:</h4>\n",
        "            <div style='display:flex; align-items:center; margin-bottom:4px;'>\n",
        "                <div style='width:50%; font-weight:bold; font-size:12px;'>{true_state}</div>\n",
        "                <div style='width:50%; font-weight:bold; font-size:12px;'>{false_state}</div>\n",
        "            </div>\n",
        "            {prob_bar}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Close the main div\n",
        "    html += \"\"\"\n",
        "    <div style='margin-top:8px; font-size:12px; color:#666; text-align:center;'>\n",
        "        Click node to see full probability details\n",
        "    </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    return html\n",
        "\n",
        "# Helper functions (get_parents, get_instantiations, get_priors, get_posteriors) remain the same\n",
        "def get_parents(row):\n",
        "    \"\"\"Extract parent nodes from row data, with safe handling for different data types\"\"\"\n",
        "    if 'Parents' not in row:\n",
        "        return []\n",
        "\n",
        "    parents_data = row['Parents']\n",
        "\n",
        "    # Handle NaN, None, or empty list\n",
        "    if isinstance(parents_data, float) and pd.isna(parents_data):\n",
        "        return []\n",
        "\n",
        "    if parents_data is None:\n",
        "        return []\n",
        "\n",
        "    # Handle different data types\n",
        "    if isinstance(parents_data, list):\n",
        "        # Return a list with NaN and empty strings removed\n",
        "        return [p for p in parents_data if not (isinstance(p, float) and pd.isna(p)) and p != '']\n",
        "\n",
        "    if isinstance(parents_data, str):\n",
        "        if not parents_data.strip():\n",
        "            return []\n",
        "\n",
        "        # Remove brackets and split by comma, removing empty strings and NaN\n",
        "        cleaned = parents_data.strip('[]\"\\'')\n",
        "        if not cleaned:\n",
        "            return []\n",
        "\n",
        "        return [p.strip(' \"\\'') for p in cleaned.split(',') if p.strip()]\n",
        "\n",
        "    # Default: empty list\n",
        "    return []\n",
        "\n",
        "def get_instantiations(row):\n",
        "    \"\"\"Extract instantiations with safe handling for different data types\"\"\"\n",
        "    if 'instantiations' not in row:\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    inst_data = row['instantiations']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if isinstance(inst_data, float) and pd.isna(inst_data):\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    if inst_data is None:\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    # Handle different data types\n",
        "    if isinstance(inst_data, list):\n",
        "        return inst_data if inst_data else [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    if isinstance(inst_data, str):\n",
        "        if not inst_data.strip():\n",
        "            return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "        # Remove brackets and split by comma\n",
        "        cleaned = inst_data.strip('[]\"\\'')\n",
        "        if not cleaned:\n",
        "            return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "        return [i.strip(' \"\\'') for i in cleaned.split(',') if i.strip()]\n",
        "\n",
        "    # Default\n",
        "    return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "def get_priors(row):\n",
        "    \"\"\"Extract prior probabilities with safe handling for different data types\"\"\"\n",
        "    if 'priors' not in row:\n",
        "        return {}\n",
        "\n",
        "    priors_data = row['priors']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if isinstance(priors_data, float) and pd.isna(priors_data):\n",
        "        return {}\n",
        "\n",
        "    if priors_data is None:\n",
        "        return {}\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Handle dictionary\n",
        "    if isinstance(priors_data, dict):\n",
        "        result = priors_data\n",
        "    # Handle string representation of dictionary\n",
        "    elif isinstance(priors_data, str):\n",
        "        if not priors_data.strip() or priors_data == '{}':\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            # Try to evaluate as Python literal\n",
        "            import ast\n",
        "            result = ast.literal_eval(priors_data)\n",
        "        except:\n",
        "            # Simple parsing for items like {'p(TRUE)': '0.2', 'p(FALSE)': '0.8'}\n",
        "            if '{' in priors_data and '}' in priors_data:\n",
        "                content = priors_data[priors_data.find('{')+1:priors_data.rfind('}')]\n",
        "                items = [item.strip() for item in content.split(',')]\n",
        "\n",
        "                for item in items:\n",
        "                    if ':' in item:\n",
        "                        key, value = item.split(':', 1)\n",
        "                        key = key.strip(' \\'\"')\n",
        "                        value = value.strip(' \\'\"')\n",
        "                        result[key] = value\n",
        "\n",
        "    # Extract main probability for TRUE state\n",
        "    instantiations = get_instantiations(row)\n",
        "    true_state = instantiations[0] if instantiations else \"TRUE\"\n",
        "    true_key = f\"p({true_state})\"\n",
        "\n",
        "    if true_key in result:\n",
        "        try:\n",
        "            result['true_prob'] = float(result[true_key])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return result\n",
        "\n",
        "def get_posteriors(row):\n",
        "    \"\"\"Extract posterior probabilities with safe handling for different data types\"\"\"\n",
        "    if 'posteriors' not in row:\n",
        "        return {}\n",
        "\n",
        "    posteriors_data = row['posteriors']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if isinstance(posteriors_data, float) and pd.isna(posteriors_data):\n",
        "        return {}\n",
        "\n",
        "    if posteriors_data is None:\n",
        "        return {}\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Handle dictionary\n",
        "    if isinstance(posteriors_data, dict):\n",
        "        result = posteriors_data\n",
        "    # Handle string representation of dictionary\n",
        "    elif isinstance(posteriors_data, str):\n",
        "        if not posteriors_data.strip() or posteriors_data == '{}':\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            # Try to evaluate as Python literal\n",
        "            import ast\n",
        "            result = ast.literal_eval(posteriors_data)\n",
        "        except:\n",
        "            # Simple parsing\n",
        "            if '{' in posteriors_data and '}' in posteriors_data:\n",
        "                content = posteriors_data[posteriors_data.find('{')+1:posteriors_data.rfind('}')]\n",
        "                items = [item.strip() for item in content.split(',')]\n",
        "\n",
        "                for item in items:\n",
        "                    if ':' in item:\n",
        "                        key, value = item.split(':', 1)\n",
        "                        key = key.strip(' \\'\"')\n",
        "                        value = value.strip(' \\'\"')\n",
        "                        result[key] = value\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "tfLqrFOFpyXK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt 3"
      ],
      "metadata": {
        "id": "vDAZfrCrrQkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bayesian_network_with_probabilities(df):\n",
        "    \"\"\"\n",
        "    Create an interactive Bayesian network visualization with enhanced probability visualization\n",
        "    and node classification based on network structure.\n",
        "    \"\"\"\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes with proper attributes\n",
        "    for idx, row in df.iterrows():\n",
        "        title = row['Title']\n",
        "        description = row['Description']\n",
        "\n",
        "        # Process probability information\n",
        "        priors = get_priors(row)\n",
        "        instantiations = get_instantiations(row)\n",
        "\n",
        "        # Add node with base information\n",
        "        G.add_node(\n",
        "            title,\n",
        "            description=description,\n",
        "            priors=priors,\n",
        "            instantiations=instantiations,\n",
        "            posteriors=get_posteriors(row)\n",
        "        )\n",
        "\n",
        "    # Add edges\n",
        "    for idx, row in df.iterrows():\n",
        "        child = row['Title']\n",
        "        parents = get_parents(row)\n",
        "\n",
        "        # Add edges from each parent to this child\n",
        "        for parent in parents:\n",
        "            if parent in G.nodes():\n",
        "                G.add_edge(parent, child)\n",
        "\n",
        "    # Classify nodes based on network structure\n",
        "    classify_nodes(G)\n",
        "\n",
        "    # Create network visualization\n",
        "    net = Network(notebook=True, directed=True, cdn_resources=\"in_line\", height=\"600px\", width=\"100%\")\n",
        "\n",
        "    # Configure physics for better layout\n",
        "    net.force_atlas_2based(gravity=-50, spring_length=100, spring_strength=0.02)\n",
        "    net.show_buttons(filter_=['physics'])\n",
        "\n",
        "    # Add the graph to the network\n",
        "    net.from_nx(G)\n",
        "\n",
        "    # Create store for expanded content to be passed to JavaScript\n",
        "    expanded_content_js = {}\n",
        "\n",
        "    # Enhance node appearance with probability information and classification\n",
        "    for node in net.nodes:\n",
        "        node_id = node['id']\n",
        "        node_data = G.nodes[node_id]\n",
        "\n",
        "        # Get node type and set border color\n",
        "        node_type = node_data.get('node_type', 'unknown')\n",
        "        border_color = get_border_color(node_type)\n",
        "\n",
        "        # Get probability and set background color\n",
        "        prob_color = get_probability_color(node_data.get('priors', {}))\n",
        "\n",
        "        # Create the node label with probability visualization\n",
        "        node_label = create_node_label(node_id, node_data)\n",
        "\n",
        "        # Create tooltip with probability information\n",
        "        tooltip = create_tooltip(node_id, node_data)\n",
        "\n",
        "        # Generate expanded content but store it separately (don't convert to JSON here)\n",
        "        expanded_content = create_expanded_content(node_id, node_data)\n",
        "        expanded_content_js[node_id] = expanded_content\n",
        "\n",
        "        # Set node attributes\n",
        "        node['title'] = tooltip  # Tooltip HTML\n",
        "        node['label'] = node_label  # Node label HTML\n",
        "        node['shape'] = 'box'\n",
        "        node['color'] = {\n",
        "            'background': prob_color,\n",
        "            'border': border_color,\n",
        "            'highlight': {\n",
        "                'background': prob_color,\n",
        "                'border': border_color\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # Save and read the HTML content\n",
        "    html_file = \"bayesian_network.html\"\n",
        "    net.save_graph(html_file)\n",
        "\n",
        "    # Inject custom js data and click handling into HTML\n",
        "    try:\n",
        "        with open(html_file, \"r\") as f:\n",
        "            html_content = f.read()\n",
        "\n",
        "        # We need to create a JS object with the expanded content in a way that preserves HTML\n",
        "        expanded_content_entries = []\n",
        "        for node_id, content in expanded_content_js.items():\n",
        "            # Properly escape the content for JavaScript string\n",
        "            js_escaped_content = json.dumps(content)\n",
        "            expanded_content_entries.append(f'\"{node_id}\": {js_escaped_content}')\n",
        "\n",
        "        # Join the entries into a JavaScript object literal\n",
        "        expanded_content_js_obj = \"{\" + \", \".join(expanded_content_entries) + \"}\"\n",
        "\n",
        "        # Create JavaScript for modal handling\n",
        "        modal_js = f\"\"\"\n",
        "        // Store expanded content for nodes\n",
        "        var expandedContentMap = {expanded_content_js_obj};\n",
        "\n",
        "        // Add event listener for node clicks\n",
        "        network.on(\"click\", function(params) {{\n",
        "            if (params.nodes.length > 0) {{\n",
        "                var nodeId = params.nodes[0];\n",
        "                var content = expandedContentMap[nodeId];\n",
        "\n",
        "                if (content) {{\n",
        "                    // Create a modal popup for expanded content\n",
        "                    var modal = document.createElement('div');\n",
        "                    modal.style.position = 'fixed';\n",
        "                    modal.style.left = '50%';\n",
        "                    modal.style.top = '50%';\n",
        "                    modal.style.transform = 'translate(-50%, -50%)';\n",
        "                    modal.style.backgroundColor = 'white';\n",
        "                    modal.style.padding = '20px';\n",
        "                    modal.style.borderRadius = '5px';\n",
        "                    modal.style.boxShadow = '0 0 10px rgba(0,0,0,0.5)';\n",
        "                    modal.style.zIndex = '1000';\n",
        "                    modal.style.maxWidth = '80%';\n",
        "                    modal.style.maxHeight = '80%';\n",
        "                    modal.style.overflow = 'auto';\n",
        "\n",
        "                    // Set the HTML content directly (no parsing needed)\n",
        "                    modal.innerHTML = content;\n",
        "\n",
        "                    // Add close button\n",
        "                    var closeBtn = document.createElement('button');\n",
        "                    closeBtn.innerHTML = 'Close';\n",
        "                    closeBtn.style.marginTop = '10px';\n",
        "                    closeBtn.style.padding = '5px 10px';\n",
        "                    closeBtn.style.cursor = 'pointer';\n",
        "                    closeBtn.onclick = function() {{\n",
        "                        document.body.removeChild(modal);\n",
        "                    }};\n",
        "                    modal.appendChild(closeBtn);\n",
        "\n",
        "                    // Add modal to body\n",
        "                    document.body.appendChild(modal);\n",
        "                }}\n",
        "            }}\n",
        "        }});\n",
        "        \"\"\"\n",
        "\n",
        "        # Insert modal JS after the network instantiation\n",
        "        html_content = html_content.replace('</script></body>', f'</script><script>{modal_js}</script></body>')\n",
        "\n",
        "        # Also fix tooltip rendering by adding this script\n",
        "        tooltip_fix_js = \"\"\"\n",
        "        // Fix tooltip rendering to properly display HTML\n",
        "        network.on(\"hoverNode\", function(params) {\n",
        "            // Find the tooltip element that gets created\n",
        "            setTimeout(function() {\n",
        "                var tooltips = document.querySelectorAll('.vis-tooltip');\n",
        "                tooltips.forEach(function(tooltip) {\n",
        "                    // This helps ensure the HTML inside the tooltip is rendered properly\n",
        "                    var content = tooltip.innerHTML;\n",
        "                    tooltip.innerHTML = content;\n",
        "                });\n",
        "            }, 0);\n",
        "        });\n",
        "        \"\"\"\n",
        "\n",
        "        # Insert tooltip fix JS after modal JS\n",
        "        html_content = html_content.replace('</script></body>', f'</script><script>{tooltip_fix_js}</script></body>')\n",
        "\n",
        "        # Write back the modified HTML\n",
        "        with open(html_file, \"w\") as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        return HTML(html_content)\n",
        "    except Exception as e:\n",
        "        return HTML(f\"<p>Error rendering HTML: {str(e)}</p><p>The network visualization has been saved to '{html_file}'</p>\")"
      ],
      "metadata": {
        "id": "eucnSy8OrS-e"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.2. Node Classification and Color Functions"
      ],
      "metadata": {
        "id": "pkTPfS8K5zHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_nodes(G):\n",
        "    \"\"\"\n",
        "    Classify nodes as parent, child, or leaf based on network structure\n",
        "    \"\"\"\n",
        "    for node in G.nodes():\n",
        "        predecessors = list(G.predecessors(node))\n",
        "        successors = list(G.successors(node))\n",
        "\n",
        "        if not predecessors:  # No parents\n",
        "            if successors:  # Has children\n",
        "                G.nodes[node]['node_type'] = 'parent'\n",
        "            else:  # No children either\n",
        "                G.nodes[node]['node_type'] = 'isolated'\n",
        "        else:  # Has parents\n",
        "            if not successors:  # No children\n",
        "                G.nodes[node]['node_type'] = 'leaf'\n",
        "            else:  # Has both parents and children\n",
        "                G.nodes[node]['node_type'] = 'child'\n",
        "\n",
        "def get_border_color(node_type):\n",
        "    \"\"\"\n",
        "    Return border color based on node type\n",
        "    \"\"\"\n",
        "    if node_type == 'parent':\n",
        "        return '#0000FF'  # Blue\n",
        "    elif node_type == 'child':\n",
        "        return '#800080'  # Purple\n",
        "    elif node_type == 'leaf':\n",
        "        return '#FF00FF'  # Magenta\n",
        "    else:\n",
        "        return '#000000'  # Default black\n",
        "\n",
        "def get_probability_color(priors):\n",
        "    \"\"\"\n",
        "    Create background color based on probability (red to green gradient)\n",
        "    \"\"\"\n",
        "    # Default to neutral color if no probability\n",
        "    if not priors or 'true_prob' not in priors:\n",
        "        return '#F8F8F8'  # Light grey\n",
        "\n",
        "    # Get probability value\n",
        "    prob = priors['true_prob']\n",
        "\n",
        "    # Create color gradient from red (0.0) to green (1.0)\n",
        "    # Using HSL for better visual gradient\n",
        "    hue = 120 * prob  # 0 = red, 120 = green (in HSL color space)\n",
        "    saturation = 0.75\n",
        "    lightness = 0.8  # Lighter color for better text visibility\n",
        "\n",
        "    # Convert HSL to RGB\n",
        "    r, g, b = colorsys.hls_to_rgb(hue/360, lightness, saturation)\n",
        "\n",
        "    # Convert to hex format\n",
        "    hex_color = \"#{:02x}{:02x}{:02x}\".format(int(r*255), int(g*255), int(b*255))\n",
        "\n",
        "    return hex_color"
      ],
      "metadata": {
        "id": "wyAboCc657ef"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.3. Probability Visualization Components"
      ],
      "metadata": {
        "id": "RR4vh7mK6Cgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_node_label(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create HTML label content for node with probability visualization\n",
        "    \"\"\"\n",
        "    priors = node_data.get('priors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # If no probability information, just return the node ID\n",
        "    if not priors or 'true_prob' not in priors:\n",
        "        return node_id\n",
        "\n",
        "    # Get probabilities\n",
        "    true_prob = priors.get('true_prob', 0.5)\n",
        "    false_prob = 1.0 - true_prob\n",
        "\n",
        "    # Get proper state names\n",
        "    true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "    false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "    # Create HTML for the node label with probability box\n",
        "    html = f\"\"\"\n",
        "    <div style=\"text-align:center; font-weight:bold;\">{node_id}</div>\n",
        "    <div style=\"margin-top:4px; display:flex; flex-direction:column; align-items:center;\">\n",
        "        <div style=\"font-size:10px;\">p({true_state})={true_prob:.3f} | p({false_state})={false_prob:.3f}</div>\n",
        "        <div style=\"width:100%; height:10px; display:flex; margin-top:2px; border:1px solid #ccc;\">\n",
        "            <div style=\"flex-basis:{true_prob*100}%; background-color:rgba(0,200,0,0.5); border-right:2px solid green;\"></div>\n",
        "            <div style=\"flex-basis:{false_prob*100}%; background-color:rgba(255,0,0,0.5); border-left:2px solid red;\"></div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Create expanded content with detailed probability information (shown on click)\n",
        "    expanded_html = create_expanded_content(node_id, node_data)\n",
        "\n",
        "    # Store both versions\n",
        "    node_data['collapsed_label'] = html\n",
        "    node_data['expanded_label'] = expanded_html\n",
        "\n",
        "    return html\n",
        "\n",
        "def create_expanded_content(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create expanded content shown when a node is clicked\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    posteriors = node_data.get('posteriors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Get proper state names\n",
        "    true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "    false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "    # Extract probabilities\n",
        "    true_prob = priors.get('true_prob', 0.5)\n",
        "    false_prob = 1.0 - true_prob\n",
        "\n",
        "    # Basic info section\n",
        "    html = f\"\"\"\n",
        "    <div style=\"max-width:300px; padding:8px; text-align:left;\">\n",
        "        <div style=\"font-weight:bold; font-size:14px;\">{node_id}</div>\n",
        "        <div style=\"font-style:italic; margin:4px 0; font-size:12px;\">{description}</div>\n",
        "\n",
        "        <div style=\"margin-top:6px; font-size:12px;\">\n",
        "            <div>Prior Probabilities:</div>\n",
        "            <div style=\"display:flex; align-items:center; margin-top:3px;\">\n",
        "                <div style=\"width:120px;\">p({true_state})={true_prob:.3f}</div>\n",
        "                <div style=\"flex-grow:1; height:14px; display:flex; border:1px solid #ccc;\">\n",
        "                    <div style=\"flex-basis:{true_prob*100}%; background-color:rgba(0,200,0,0.5); border-right:2px solid green;\"></div>\n",
        "                    <div style=\"flex-basis:{false_prob*100}%; background-color:rgba(255,0,0,0.5); border-left:2px solid red;\"></div>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add conditional probability table if available\n",
        "    if posteriors:\n",
        "        html += \"\"\"\n",
        "        <div style=\"margin-top:8px; font-size:12px;\">\n",
        "            <div>Conditional Probabilities:</div>\n",
        "            <table style=\"width:100%; border-collapse:collapse; margin-top:3px; font-size:10px;\">\n",
        "                <tr style=\"background-color:#f0f0f0;\">\n",
        "                    <th style=\"padding:2px; text-align:left; border:1px solid #ccc;\">Condition</th>\n",
        "                    <th style=\"padding:2px; text-align:center; border:1px solid #ccc;\">Value</th>\n",
        "                    <th style=\"padding:2px; text-align:center; border:1px solid #ccc;\">Visualization</th>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        # Add rows for conditional probabilities\n",
        "        for i, (key, value) in enumerate(posteriors.items()):\n",
        "            try:\n",
        "                prob_value = float(value)\n",
        "                # Create visualization for this probability\n",
        "                html += f\"\"\"\n",
        "                <tr>\n",
        "                    <td style=\"padding:2px; border:1px solid #ccc;\">{key}</td>\n",
        "                    <td style=\"padding:2px; text-align:center; border:1px solid #ccc;\">{value}</td>\n",
        "                    <td style=\"padding:2px; border:1px solid #ccc;\">\n",
        "                        <div style=\"width:100%; height:12px; display:flex;\">\n",
        "                            <div style=\"flex-basis:{prob_value*100}%; background-color:rgba(0,200,0,0.5); border-right:2px solid green;\"></div>\n",
        "                            <div style=\"flex-basis:{(1.0-prob_value)*100}%; background-color:rgba(255,0,0,0.5); border-left:2px solid red;\"></div>\n",
        "                        </div>\n",
        "                    </td>\n",
        "                </tr>\n",
        "                \"\"\"\n",
        "            except:\n",
        "                # Fallback for non-numeric values\n",
        "                html += f\"\"\"\n",
        "                <tr>\n",
        "                    <td style=\"padding:2px; border:1px solid #ccc;\">{key}</td>\n",
        "                    <td style=\"padding:2px; text-align:center; border:1px solid #ccc;\" colspan=\"2\">{value}</td>\n",
        "                </tr>\n",
        "                \"\"\"\n",
        "\n",
        "        html += \"\"\"\n",
        "            </table>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Add click instruction\n",
        "    html += \"\"\"\n",
        "    <div style=\"margin-top:8px; font-size:10px; color:#666; text-align:center;\">\n",
        "        Click again to collapse\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    html += \"</div>\"\n",
        "\n",
        "    return html"
      ],
      "metadata": {
        "id": "3_Mez8ph6GAr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.4. Enhanced Tooltip Generation"
      ],
      "metadata": {
        "id": "LNzjL1iO6IsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tooltip(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create rich HTML tooltip with probability information and visualizations\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Start building the HTML tooltip\n",
        "    html = f\"\"\"\n",
        "    <div style='max-width:350px; padding:10px; background-color:#f8f9fa; border-radius:5px; font-family:Arial, sans-serif;'>\n",
        "        <h3 style='margin-top:0; color:#202124;'>{node_id}</h3>\n",
        "        <p style='font-style:italic;'>{description}</p>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add prior probabilities section with visualization\n",
        "    if priors and 'true_prob' in priors:\n",
        "        true_prob = priors['true_prob']\n",
        "        false_prob = 1.0 - true_prob\n",
        "\n",
        "        # Get proper state names\n",
        "        true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "        false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <div style='margin-top:10px; background-color:#fff; padding:8px; border-radius:4px; border:1px solid #ddd;'>\n",
        "            <h4 style='margin-top:0; font-size:14px;'>Prior Probabilities:</h4>\n",
        "            <div style='display:flex; align-items:center; margin-bottom:4px;'>\n",
        "                <div style='width:50%; font-weight:bold;'>{true_state}: {true_prob:.3f}</div>\n",
        "                <div style='width:50%; font-weight:bold;'>{false_state}: {false_prob:.3f}</div>\n",
        "            </div>\n",
        "            <div style='width:100%; height:20px; display:flex; border:1px solid #ccc;'>\n",
        "                <div style='width:{true_prob*100}%; background-color:rgba(0,200,0,0.5); border-right:2px solid green;'></div>\n",
        "                <div style='width:{false_prob*100}%; background-color:rgba(255,0,0,0.5); border-left:2px solid red;'></div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Close the main div\n",
        "    html += \"\"\"\n",
        "    <div style='margin-top:8px; font-size:12px; color:#666; text-align:center;'>\n",
        "        Click node to see full probability details\n",
        "    </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    return html"
      ],
      "metadata": {
        "id": "4Qrr4wP26LIy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_probability_bar(true_prob, false_prob, height=\"15px\", show_values=True, value_prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Creates a reusable HTML component to visualize probability distribution\n",
        "    \"\"\"\n",
        "    true_label = f\"{value_prefix}{true_prob:.3f}\" if show_values else \"\"\n",
        "    false_label = f\"{value_prefix}{false_prob:.3f}\" if show_values else \"\"\n",
        "\n",
        "    html = f\"\"\"\n",
        "    <div style=\"width:100%; height:{height}; display:flex; border:1px solid #ccc; overflow:hidden; border-radius:3px; margin-top:3px; margin-bottom:3px;\">\n",
        "        <div style=\"flex-basis:{true_prob*100}%; background:linear-gradient(to bottom, rgba(0,180,0,0.9), rgba(0,140,0,0.7)); border-right:2px solid #008800; display:flex; align-items:center; justify-content:center; overflow:hidden; min-width:{2 if true_prob > 0 else 0}px;\">\n",
        "            <span style=\"font-size:10px; color:white; text-shadow:0px 0px 2px #000;\">{true_label}</span>\n",
        "        </div>\n",
        "        <div style=\"flex-basis:{false_prob*100}%; background:linear-gradient(to bottom, rgba(220,0,0,0.9), rgba(180,0,0,0.7)); border-left:2px solid #880000; display:flex; align-items:center; justify-content:center; overflow:hidden; min-width:{2 if false_prob > 0 else 0}px;\">\n",
        "            <span style=\"font-size:10px; color:white; text-shadow:0px 0px 2px #000;\">{false_label}</span>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "def create_node_label(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create HTML label content for node with probability visualization\n",
        "    \"\"\"\n",
        "    priors = node_data.get('priors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # If no probability information, just return the node ID\n",
        "    if not priors or 'true_prob' not in priors:\n",
        "        return f'<div style=\"text-align:center; font-weight:bold;\">{node_id}</div>'\n",
        "\n",
        "    # Get probabilities\n",
        "    true_prob = priors.get('true_prob', 0.5)\n",
        "    false_prob = 1.0 - true_prob\n",
        "\n",
        "    # Create HTML for the node label with probability box\n",
        "    html = f\"\"\"\n",
        "    <div style=\"text-align:center; font-weight:bold;\">{node_id}</div>\n",
        "    <div style=\"margin-top:4px; font-size:10px; text-align:center;\">p={true_prob:.2f}</div>\n",
        "    <div style=\"width:100%; height:10px; display:flex; margin:2px 0; border:1px solid #ccc;\">\n",
        "        <div style=\"width:{true_prob*100}%; background-color:rgba(0,200,0,0.9); border-right:2px solid green;\"></div>\n",
        "        <div style=\"width:{false_prob*100}%; background-color:rgba(255,0,0,0.9); border-left:2px solid red;\"></div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    return html\n",
        "\n",
        "def create_tooltip(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create rich HTML tooltip with probability information\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Build a cleaner tooltip that will render correctly\n",
        "    html = f\"\"\"\n",
        "    <div style=\"width:300px; padding:10px; background-color:#f8f9fa; border-radius:5px; font-family:Arial, sans-serif;\">\n",
        "        <h3 style=\"margin-top:0; color:#202124;\">{node_id}</h3>\n",
        "        <p style=\"font-style:italic;\">{description}</p>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add prior probabilities section\n",
        "    if priors and 'true_prob' in priors:\n",
        "        true_prob = priors['true_prob']\n",
        "        false_prob = 1.0 - true_prob\n",
        "\n",
        "        # Get proper state names\n",
        "        true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "        false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <div style=\"margin-top:10px; background-color:#fff; padding:8px; border-radius:4px; border:1px solid #ddd;\">\n",
        "            <h4 style=\"margin-top:0; font-size:14px;\">Prior Probabilities:</h4>\n",
        "            <div style=\"display:flex; justify-content:space-between; margin-bottom:4px;\">\n",
        "                <div style=\"font-size:12px;\">{true_state}: {true_prob:.3f}</div>\n",
        "                <div style=\"font-size:12px;\">{false_state}: {false_prob:.3f}</div>\n",
        "            </div>\n",
        "            <div style=\"width:100%; height:20px; display:flex; border:1px solid #ccc;\">\n",
        "                <div style=\"width:{true_prob*100}%; background-color:rgba(0,200,0,0.9); border-right:2px solid green;\"></div>\n",
        "                <div style=\"width:{false_prob*100}%; background-color:rgba(255,0,0,0.9); border-left:2px solid red;\"></div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Add click instruction\n",
        "    html += \"\"\"\n",
        "    <div style=\"margin-top:8px; font-size:12px; color:#666; text-align:center;\">\n",
        "        Click node to see full probability details\n",
        "    </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    return html\n",
        "\n",
        "def create_expanded_content(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create expanded content shown when a node is clicked\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    posteriors = node_data.get('posteriors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Get proper state names\n",
        "    true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "    false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "    # Extract probabilities\n",
        "    true_prob = priors.get('true_prob', 0.5)\n",
        "    false_prob = 1.0 - true_prob\n",
        "\n",
        "    # Start building the expanded content\n",
        "    html = f\"\"\"\n",
        "    <div style=\"max-width:500px; padding:15px; font-family:Arial, sans-serif;\">\n",
        "        <h2 style=\"margin-top:0; color:#333;\">{node_id}</h2>\n",
        "        <p style=\"font-style:italic; margin-bottom:15px;\">{description}</p>\n",
        "\n",
        "        <div style=\"margin-bottom:20px; padding:12px; border:1px solid #ddd; background-color:#f9f9f9; border-radius:5px;\">\n",
        "            <h3 style=\"margin-top:0; color:#333;\">Prior Probabilities</h3>\n",
        "            <div style=\"display:flex; justify-content:space-between; margin-bottom:5px;\">\n",
        "                <div><strong>{true_state}:</strong> {true_prob:.3f}</div>\n",
        "                <div><strong>{false_state}:</strong> {false_prob:.3f}</div>\n",
        "            </div>\n",
        "            <div style=\"width:100%; height:25px; display:flex; border:1px solid #ccc; border-radius:3px;\">\n",
        "                <div style=\"width:{true_prob*100}%; background:linear-gradient(to bottom, rgba(0,180,0,0.9), rgba(0,140,0,0.7)); border-right:2px solid #008800; display:flex; align-items:center; justify-content:center;\">\n",
        "                    <span style=\"font-size:12px; color:white; text-shadow:0px 0px 2px #000;\">{true_prob:.3f}</span>\n",
        "                </div>\n",
        "                <div style=\"width:{false_prob*100}%; background:linear-gradient(to bottom, rgba(220,0,0,0.9), rgba(180,0,0,0.7)); border-left:2px solid #880000; display:flex; align-items:center; justify-content:center;\">\n",
        "                    <span style=\"font-size:12px; color:white; text-shadow:0px 0px 2px #000;\">{false_prob:.3f}</span>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add conditional probability table if available\n",
        "    if posteriors:\n",
        "        html += \"\"\"\n",
        "        <div style=\"padding:12px; border:1px solid #ddd; background-color:#f9f9f9; border-radius:5px;\">\n",
        "            <h3 style=\"margin-top:0; color:#333;\">Conditional Probabilities</h3>\n",
        "            <table style=\"width:100%; border-collapse:collapse; font-size:13px;\">\n",
        "                <tr style=\"background-color:#eee;\">\n",
        "                    <th style=\"padding:8px; text-align:left; border:1px solid #ddd;\">Condition</th>\n",
        "                    <th style=\"padding:8px; text-align:center; border:1px solid #ddd; width:80px;\">Value</th>\n",
        "                    <th style=\"padding:8px; text-align:center; border:1px solid #ddd;\">Visualization</th>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        # Sort posteriors to group by similar conditions\n",
        "        posterior_items = list(posteriors.items())\n",
        "        posterior_items.sort(key=lambda x: x[0])\n",
        "\n",
        "        # Add rows for conditional probabilities\n",
        "        for key, value in posterior_items:\n",
        "            try:\n",
        "                # Try to parse probability value\n",
        "                prob_value = float(value)\n",
        "                inv_prob = 1.0 - prob_value\n",
        "\n",
        "                # Add row with probability visualization\n",
        "                html += f\"\"\"\n",
        "                <tr>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">{key}</td>\n",
        "                    <td style=\"padding:8px; text-align:center; border:1px solid #ddd;\">{prob_value:.3f}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">\n",
        "                        <div style=\"width:100%; height:20px; display:flex; border:1px solid #ccc; border-radius:3px;\">\n",
        "                            <div style=\"width:{prob_value*100}%; background:linear-gradient(to bottom, rgba(0,180,0,0.9), rgba(0,140,0,0.7)); display:flex; align-items:center; justify-content:center; min-width:{2 if prob_value > 0 else 0}px;\">\n",
        "                            </div>\n",
        "                            <div style=\"width:{inv_prob*100}%; background:linear-gradient(to bottom, rgba(220,0,0,0.9), rgba(180,0,0,0.7)); display:flex; align-items:center; justify-content:center; min-width:{2 if inv_prob > 0 else 0}px;\">\n",
        "                            </div>\n",
        "                        </div>\n",
        "                    </td>\n",
        "                </tr>\n",
        "                \"\"\"\n",
        "            except:\n",
        "                # Fallback for non-numeric values\n",
        "                html += f\"\"\"\n",
        "                <tr>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">{key}</td>\n",
        "                    <td style=\"padding:8px; text-align:center; border:1px solid #ddd;\" colspan=\"2\">{value}</td>\n",
        "                </tr>\n",
        "                \"\"\"\n",
        "\n",
        "        html += \"\"\"\n",
        "            </table>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    html += \"</div>\"\n",
        "\n",
        "    return html\n",
        "\n",
        "def get_probability_color(priors):\n",
        "    \"\"\"\n",
        "    Create background color based on probability (red to green gradient)\n",
        "    \"\"\"\n",
        "    # Default to neutral color if no probability\n",
        "    if not priors or 'true_prob' not in priors:\n",
        "        return '#F8F8F8'  # Light grey\n",
        "\n",
        "    # Get probability value\n",
        "    prob = priors['true_prob']\n",
        "\n",
        "    # Create color gradient from red (0.0) to green (1.0)\n",
        "    # Using HSL for better visual gradient\n",
        "    hue = 120 * prob  # 0 = red, 120 = green (in HSL color space)\n",
        "    saturation = 0.95  # Increased saturation for more vibrant colors\n",
        "    lightness = 0.75  # Slightly lighter for better text visibility\n",
        "\n",
        "    # Convert HSL to RGB\n",
        "    r, g, b = colorsys.hls_to_rgb(hue/360, lightness, saturation)\n",
        "\n",
        "    # Convert to hex format\n",
        "    hex_color = \"#{:02x}{:02x}{:02x}\".format(int(r*255), int(g*255), int(b*255))\n",
        "\n",
        "    return hex_color"
      ],
      "metadata": {
        "id": "8jWHqWRArk8O"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.5. Existing Helper Functions (Modified for Robustness)"
      ],
      "metadata": {
        "id": "ZtKJ5SYm6Nf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parents(row):\n",
        "    \"\"\"Extract parent nodes from row data, with safe handling for different data types\"\"\"\n",
        "    if 'Parents' not in row:\n",
        "        return []\n",
        "\n",
        "    parents_data = row['Parents']\n",
        "\n",
        "    # Handle NaN, None, or empty list\n",
        "    if isinstance(parents_data, float) and pd.isna(parents_data):\n",
        "        return []\n",
        "\n",
        "    if parents_data is None:\n",
        "        return []\n",
        "\n",
        "    # Handle different data types\n",
        "    if isinstance(parents_data, list):\n",
        "        # Return a list with NaN and empty strings removed\n",
        "        return [p for p in parents_data if not (isinstance(p, float) and pd.isna(p)) and p != '']\n",
        "\n",
        "    if isinstance(parents_data, str):\n",
        "        if not parents_data.strip():\n",
        "            return []\n",
        "\n",
        "        # Remove brackets and split by comma, removing empty strings and NaN\n",
        "        cleaned = parents_data.strip('[]\"\\'')\n",
        "        if not cleaned:\n",
        "            return []\n",
        "\n",
        "        return [p.strip(' \"\\'') for p in cleaned.split(',') if p.strip()]\n",
        "\n",
        "    # Default: empty list\n",
        "    return []\n",
        "\n",
        "def get_instantiations(row):\n",
        "    \"\"\"Extract instantiations with safe handling for different data types\"\"\"\n",
        "    if 'instantiations' not in row:\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    inst_data = row['instantiations']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if isinstance(inst_data, float) and pd.isna(inst_data):\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    if inst_data is None:\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    # Handle different data types\n",
        "    if isinstance(inst_data, list):\n",
        "        return inst_data if inst_data else [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    if isinstance(inst_data, str):\n",
        "        if not inst_data.strip():\n",
        "            return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "        # Remove brackets and split by comma\n",
        "        cleaned = inst_data.strip('[]\"\\'')\n",
        "        if not cleaned:\n",
        "            return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "        return [i.strip(' \"\\'') for i in cleaned.split(',') if i.strip()]\n",
        "\n",
        "    # Default\n",
        "    return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "def get_priors(row):\n",
        "    \"\"\"Extract prior probabilities with safe handling for different data types\"\"\"\n",
        "    if 'priors' not in row:\n",
        "        return {}\n",
        "\n",
        "    priors_data = row['priors']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if isinstance(priors_data, float) and pd.isna(priors_data):\n",
        "        return {}\n",
        "\n",
        "    if priors_data is None:\n",
        "        return {}\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Handle dictionary\n",
        "    if isinstance(priors_data, dict):\n",
        "        result = priors_data\n",
        "    # Handle string representation of dictionary\n",
        "    elif isinstance(priors_data, str):\n",
        "        if not priors_data.strip() or priors_data == '{}':\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            # Try to evaluate as Python literal\n",
        "            import ast\n",
        "            result = ast.literal_eval(priors_data)\n",
        "        except:\n",
        "            # Simple parsing for items like {'p(TRUE)': '0.2', 'p(FALSE)': '0.8'}\n",
        "            if '{' in priors_data and '}' in priors_data:\n",
        "                content = priors_data[priors_data.find('{')+1:priors_data.rfind('}')]\n",
        "                items = [item.strip() for item in content.split(',')]\n",
        "\n",
        "                for item in items:\n",
        "                    if ':' in item:\n",
        "                        key, value = item.split(':', 1)\n",
        "                        key = key.strip(' \\'\"')\n",
        "                        value = value.strip(' \\'\"')\n",
        "                        result[key] = value\n",
        "\n",
        "    # Extract main probability for TRUE state\n",
        "    instantiations = get_instantiations(row)\n",
        "    true_state = instantiations[0] if instantiations else \"TRUE\"\n",
        "    true_key = f\"p({true_state})\"\n",
        "\n",
        "    if true_key in result:\n",
        "        try:\n",
        "            result['true_prob'] = float(result[true_key])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return result\n",
        "\n",
        "def get_posteriors(row):\n",
        "    \"\"\"Extract posterior probabilities with safe handling for different data types\"\"\"\n",
        "    if 'posteriors' not in row:\n",
        "        return {}\n",
        "\n",
        "    posteriors_data = row['posteriors']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if isinstance(posteriors_data, float) and pd.isna(posteriors_data):\n",
        "        return {}\n",
        "\n",
        "    if posteriors_data is None:\n",
        "        return {}\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Handle dictionary\n",
        "    if isinstance(posteriors_data, dict):\n",
        "        result = posteriors_data\n",
        "    # Handle string representation of dictionary\n",
        "    elif isinstance(posteriors_data, str):\n",
        "        if not posteriors_data.strip() or posteriors_data == '{}':\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            # Try to evaluate as Python literal\n",
        "            import ast\n",
        "            result = ast.literal_eval(posteriors_data)\n",
        "        except:\n",
        "            # Simple parsing\n",
        "            if '{' in posteriors_data and '}' in posteriors_data:\n",
        "                content = posteriors_data[posteriors_data.find('{')+1:posteriors_data.rfind('}')]\n",
        "                items = [item.strip() for item in content.split(',')]\n",
        "\n",
        "                for item in items:\n",
        "                    if ':' in item:\n",
        "                        key, value = item.split(':', 1)\n",
        "                        key = key.strip(' \\'\"')\n",
        "                        value = value.strip(' \\'\"')\n",
        "                        result[key] = value\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "pDC6xxCa6RHV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.6. Usage and Integration"
      ],
      "metadata": {
        "id": "UjkiuvIt6WL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VrmuRTE8Nhx",
        "outputId": "3ef8cb09-6e24-48bc-c77a-e5fc93191d12"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Title                                        Description  line  \\\n",
            "0  Grass_Wet  Concentrated moisture on, between and around t...     3   \n",
            "1       Rain  Tears of angles crying high up in the skies hi...     4   \n",
            "2  Sprinkler  Activation of a centrifugal force based CO2 dr...     5   \n",
            "\n",
            "  line_numbers  indentation indentation_levels            Parents  \\\n",
            "0          [3]            0                [0]  [Rain, Sprinkler]   \n",
            "1       [4, 6]            2             [1, 2]                 []   \n",
            "2          [5]            1                [1]             [Rain]   \n",
            "\n",
            "                 Children                     instantiations  \\\n",
            "0                      []  [grass_wet_TRUE, grass_wet_FALSE]   \n",
            "1  [Grass_Wet, Sprinkler]            [rain_TRUE, rain_FALSE]   \n",
            "2             [Grass_Wet]  [sprinkler_TRUE, sprinkler_FALSE]   \n",
            "\n",
            "                                              priors  \\\n",
            "0  {'p(grass_wet_TRUE)': '0.322', 'p(grass_wet_FA...   \n",
            "1    {'p(rain_TRUE)': '0.2', 'p(rain_FALSE)': '0.8'}   \n",
            "2  {'p(sprinkler_TRUE)': '0.44838', 'p(sprinkler_...   \n",
            "\n",
            "                                          posteriors  No_Parent  No_Children  \n",
            "0  {'p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)':...      False         True  \n",
            "1                                                 {}       True        False  \n",
            "2  {'p(sprinkler_TRUE|rain_TRUE)': '0.01', 'p(spr...      False        False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the function to create and display the visualization\n",
        "# This would typically be called with the result_df from the data extraction\n",
        "\n",
        "# create_bayesian_network_with_probabilities(result_df)"
      ],
      "metadata": {
        "id": "MpFi1IAb6Y9a"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Simple Network"
      ],
      "metadata": {
        "id": "TWyIYmat5oJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyvis.network import Network\n",
        "import networkx as nx\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import base64\n",
        "\n",
        "def create_bayesian_network_with_probabilities(df):\n",
        "    \"\"\"\n",
        "    Create an interactive Bayesian network visualization with probability information\n",
        "    displayed in tooltips and through visual encoding\n",
        "    \"\"\"\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes with proper attributes\n",
        "    for idx, row in df.iterrows():\n",
        "        title = row['Title']\n",
        "        description = row['Description']\n",
        "\n",
        "        # Process probability information\n",
        "        priors = get_priors(row)\n",
        "        instantiations = get_instantiations(row)\n",
        "\n",
        "        # Add node with base information\n",
        "        G.add_node(\n",
        "            title,\n",
        "            description=description,\n",
        "            priors=priors,\n",
        "            instantiations=instantiations,\n",
        "            posteriors=get_posteriors(row)\n",
        "        )\n",
        "\n",
        "    # Add edges\n",
        "    for idx, row in df.iterrows():\n",
        "        child = row['Title']\n",
        "        parents = get_parents(row)\n",
        "\n",
        "        # Add edges from each parent to this child\n",
        "        for parent in parents:\n",
        "            if parent in G.nodes():\n",
        "                G.add_edge(parent, child)\n",
        "\n",
        "    # Create network visualization\n",
        "    net = Network(notebook=True, directed=True, cdn_resources=\"in_line\", height=\"600px\", width=\"100%\")\n",
        "\n",
        "    # Configure physics for better layout\n",
        "    net.force_atlas_2based(gravity=-50, spring_length=100, spring_strength=0.02)\n",
        "    net.show_buttons(filter_=['physics'])\n",
        "\n",
        "    # Add the graph to the network\n",
        "    net.from_nx(G)\n",
        "\n",
        "    # Enhance node appearance with probability information\n",
        "    for node in net.nodes:\n",
        "        node_id = node['id']\n",
        "        node_data = G.nodes[node_id]\n",
        "\n",
        "        # Create tooltip with probability information\n",
        "        tooltip = create_tooltip(node_id, node_data)\n",
        "\n",
        "        # Determine node color based on node type\n",
        "        if list(G.predecessors(node_id)):  # Has parents\n",
        "            if list(G.successors(node_id)):  # Also has children\n",
        "                color = \"#FBBC05\"  # Orange for intermediate nodes\n",
        "            else:\n",
        "                color = \"#34A853\"  # Green for leaf nodes\n",
        "        else:\n",
        "            color = \"#4285F4\"  # Blue for root nodes\n",
        "\n",
        "        # Set node attributes\n",
        "        node['title'] = tooltip\n",
        "        node['shape'] = 'box'\n",
        "        node['color'] = color\n",
        "\n",
        "        # Add marginal probability to label if available\n",
        "        priors = node_data.get('priors', {})\n",
        "        if priors and 'true_prob' in priors:\n",
        "            prob = priors['true_prob']\n",
        "            node['label'] = f\"{node_id}\\np={prob:.2f}\"\n",
        "        else:\n",
        "            node['label'] = node_id\n",
        "\n",
        "    # Save and read the HTML content\n",
        "    html_file = \"bayesian_network.html\"\n",
        "    net.save_graph(html_file)\n",
        "\n",
        "    try:\n",
        "        with open(html_file, \"r\") as f:\n",
        "            html_content = f.read()\n",
        "        return HTML(html_content)\n",
        "    except Exception as e:\n",
        "        return HTML(f\"<p>Error rendering HTML: {str(e)}</p><p>The network visualization has been saved to '{html_file}'</p>\")\n",
        "\n",
        "def get_parents(row):\n",
        "    \"\"\"Extract parent nodes from row data, with safe handling for different data types\"\"\"\n",
        "    if 'Parents' not in row:\n",
        "        return []\n",
        "\n",
        "    parents_data = row['Parents']\n",
        "\n",
        "    # Handle NaN, None, or empty list (More robust)\n",
        "    # Using any() or all() to resolve ambiguity\n",
        "    if pd.isna(parents_data).any() or (isinstance(parents_data, (list, np.ndarray, str)) and (len(parents_data) == 0 or (isinstance(parents_data, str) and parents_data.strip() == ''))):\n",
        "        return []\n",
        "\n",
        "    # Handle different data types\n",
        "    if isinstance(parents_data, list):\n",
        "        # Return a list with NaN and empty strings removed\n",
        "        return [p for p in parents_data if not pd.isna(p) and p != '']\n",
        "\n",
        "    if isinstance(parents_data, str):\n",
        "        if not parents_data.strip():\n",
        "            return []\n",
        "\n",
        "        # Remove brackets and split by comma, removing empty strings and NaN\n",
        "        cleaned = parents_data.strip('[]\"\\'')\n",
        "        if not cleaned:\n",
        "            return []\n",
        "\n",
        "        return [p.strip(' \"\\'') for p in cleaned.split(',') if p.strip() and not pd.isna(p)]\n",
        "\n",
        "    # Default: empty list\n",
        "    return []\n",
        "\n",
        "def get_instantiations(row):\n",
        "    \"\"\"Extract instantiations with safe handling for different data types\"\"\"\n",
        "    if 'instantiations' not in row:\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    inst_data = row['instantiations']\n",
        "\n",
        "    # Handle NaN or None (Corrected condition)\n",
        "    if pd.isna(inst_data).any():  # or pd.isnull(inst_data).any()\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    # ... (Rest of the function remains the same)\n",
        "\n",
        "    # Handle different data types\n",
        "    if isinstance(inst_data, list):\n",
        "        return inst_data if inst_data else [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    if isinstance(inst_data, str):\n",
        "        if not inst_data.strip():\n",
        "            return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "        # Remove brackets and split by comma\n",
        "        cleaned = inst_data.strip('[]\"\\'')\n",
        "        if not cleaned:\n",
        "            return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "        return [i.strip(' \"\\'') for i in cleaned.split(',') if i.strip()]\n",
        "\n",
        "    # Default\n",
        "    return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "def get_priors(row):\n",
        "    \"\"\"Extract prior probabilities with safe handling for different data types\"\"\"\n",
        "    if 'priors' not in row:\n",
        "        return {}\n",
        "\n",
        "    priors_data = row['priors']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if pd.isna(priors_data):\n",
        "        return {}\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Handle dictionary\n",
        "    if isinstance(priors_data, dict):\n",
        "        result = priors_data\n",
        "    # Handle string representation of dictionary\n",
        "    elif isinstance(priors_data, str):\n",
        "        if not priors_data.strip() or priors_data == '{}':\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            # Try to evaluate as Python literal\n",
        "            result = eval(priors_data)\n",
        "        except:\n",
        "            # Simple parsing for items like {'p(TRUE)': '0.2', 'p(FALSE)': '0.8'}\n",
        "            if '{' in priors_data and '}' in priors_data:\n",
        "                content = priors_data[priors_data.find('{')+1:priors_data.rfind('}')]\n",
        "                items = [item.strip() for item in content.split(',')]\n",
        "\n",
        "                for item in items:\n",
        "                    if ':' in item:\n",
        "                        key, value = item.split(':', 1)\n",
        "                        key = key.strip(' \\'\"')\n",
        "                        value = value.strip(' \\'\"')\n",
        "                        result[key] = value\n",
        "\n",
        "    # Extract main probability for TRUE state\n",
        "    instantiations = get_instantiations(row)\n",
        "    true_state = instantiations[0] if instantiations else \"TRUE\"\n",
        "    true_key = f\"p({true_state})\"\n",
        "\n",
        "    if true_key in result:\n",
        "        try:\n",
        "            result['true_prob'] = float(result[true_key])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return result\n",
        "\n",
        "def get_posteriors(row):\n",
        "    \"\"\"Extract posterior probabilities with safe handling for different data types\"\"\"\n",
        "    if 'posteriors' not in row:\n",
        "        return {}\n",
        "\n",
        "    posteriors_data = row['posteriors']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if pd.isna(posteriors_data):\n",
        "        return {}\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Handle dictionary\n",
        "    if isinstance(posteriors_data, dict):\n",
        "        result = posteriors_data\n",
        "    # Handle string representation of dictionary\n",
        "    elif isinstance(posteriors_data, str):\n",
        "        if not posteriors_data.strip() or posteriors_data == '{}':\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            # Try to evaluate as Python literal\n",
        "            result = eval(posteriors_data)\n",
        "        except:\n",
        "            # Simple parsing\n",
        "            if '{' in posteriors_data and '}' in posteriors_data:\n",
        "                content = posteriors_data[posteriors_data.find('{')+1:posteriors_data.rfind('}')]\n",
        "                items = [item.strip() for item in content.split(',')]\n",
        "\n",
        "                for item in items:\n",
        "                    if ':' in item:\n",
        "                        key, value = item.split(':', 1)\n",
        "                        key = key.strip(' \\'\"')\n",
        "                        value = value.strip(' \\'\"')\n",
        "                        result[key] = value\n",
        "\n",
        "    return result\n",
        "\n",
        "def create_tooltip(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create rich HTML tooltip with probability information\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    posteriors = node_data.get('posteriors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Start building the HTML tooltip\n",
        "    html = f\"\"\"\n",
        "    <div style='max-width:350px; padding:10px; background-color:#f8f9fa; border-radius:5px; font-family:Arial, sans-serif;'>\n",
        "        <h3 style='margin-top:0; color:#202124;'>{node_id}</h3>\n",
        "        <p style='font-style:italic;'>{description}</p>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add chart if possible\n",
        "    chart_html = create_simple_chart(node_id, priors, instantiations)\n",
        "    if chart_html:\n",
        "        html += f\"\"\"\n",
        "        <div style='margin:10px 0; text-align:center;'>\n",
        "            {chart_html}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Add prior probabilities section\n",
        "    if priors:\n",
        "        html += \"\"\"\n",
        "        <div style='margin-top:10px; background-color:#fff; padding:8px; border-radius:4px; border:1px solid #ddd;'>\n",
        "            <h4 style='margin-top:0; font-size:14px;'>Prior Probabilities:</h4>\n",
        "            <table style='width:100%; border-collapse:collapse;'>\n",
        "                <tr style='background-color:#f1f3f4;'>\n",
        "                    <th style='padding:4px; text-align:left; border:1px solid #ddd;'>State</th>\n",
        "                    <th style='padding:4px; text-align:right; border:1px solid #ddd;'>Probability</th>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        for i, state in enumerate(instantiations):\n",
        "            key = f\"p({state})\"\n",
        "            if key in priors:\n",
        "                value = priors[key]\n",
        "                try:\n",
        "                    prob = float(value)\n",
        "                    # Add visualization bar\n",
        "                    html += f\"\"\"\n",
        "                    <tr>\n",
        "                        <td style='padding:4px; border:1px solid #ddd;'>{state}</td>\n",
        "                        <td style='padding:4px; text-align:right; border:1px solid #ddd;'>\n",
        "                            <div style='background:#e8f0fe; width:100%; height:18px; position:relative;'>\n",
        "                                <div style='position:absolute; height:100%; width:{prob*100}%; background:#4285f4;'></div>\n",
        "                                <span style='position:relative; z-index:1;'>{value}</span>\n",
        "                            </div>\n",
        "                        </td>\n",
        "                    </tr>\n",
        "                    \"\"\"\n",
        "                except:\n",
        "                    html += f\"\"\"\n",
        "                    <tr>\n",
        "                        <td style='padding:4px; border:1px solid #ddd;'>{state}</td>\n",
        "                        <td style='padding:4px; text-align:right; border:1px solid #ddd;'>{value}</td>\n",
        "                    </tr>\n",
        "                    \"\"\"\n",
        "\n",
        "        html += \"\"\"\n",
        "            </table>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Add conditional probabilities section (simplified)\n",
        "    if posteriors:\n",
        "        html += \"\"\"\n",
        "        <div style='margin-top:10px; background-color:#fff; padding:8px; border-radius:4px; border:1px solid #ddd;'>\n",
        "            <h4 style='margin-top:0; font-size:14px;'>Conditional Probabilities:</h4>\n",
        "            <div style='max-height:150px; overflow-y:auto;'>\n",
        "                <table style='width:100%; border-collapse:collapse;'>\n",
        "                    <tr style='background-color:#f1f3f4;'>\n",
        "                        <th style='padding:4px; text-align:left; border:1px solid #ddd;'>Condition</th>\n",
        "                        <th style='padding:4px; text-align:right; border:1px solid #ddd;'>Value</th>\n",
        "                    </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        # Add first few conditional probabilities\n",
        "        for i, (key, value) in enumerate(list(posteriors.items())[:8]):\n",
        "            html += f\"\"\"\n",
        "            <tr>\n",
        "                <td style='padding:4px; border:1px solid #ddd;'>{key}</td>\n",
        "                <td style='padding:4px; text-align:right; border:1px solid #ddd;'>{value}</td>\n",
        "            </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        # Show if there are more\n",
        "        if len(posteriors) > 8:\n",
        "            html += f\"\"\"\n",
        "            <tr>\n",
        "                <td colspan='2' style='padding:4px; text-align:center; border:1px solid #ddd;'>\n",
        "                    (+{len(posteriors) - 8} more)\n",
        "                </td>\n",
        "            </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        html += \"\"\"\n",
        "                </table>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Close the main div\n",
        "    html += \"</div>\"\n",
        "\n",
        "    return html\n",
        "\n",
        "def create_simple_chart(node_id, priors, instantiations):\n",
        "    \"\"\"\n",
        "    Create a simple probability chart as an embedded image\n",
        "    \"\"\"\n",
        "    # Check if we have necessary information\n",
        "    if 'true_prob' not in priors:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        # Set up the values for visualization\n",
        "        labels = instantiations[:2]  # Use first two states\n",
        "        values = []\n",
        "\n",
        "        # Get probability for first state\n",
        "        true_prob = priors['true_prob']\n",
        "        values.append(true_prob)\n",
        "\n",
        "        # Calculate second state probability\n",
        "        if len(labels) > 1:\n",
        "            values.append(1.0 - true_prob)\n",
        "\n",
        "        # Create the chart\n",
        "        plt.figure(figsize=(3, 2))\n",
        "        bars = plt.bar(labels, values, color=['#4285F4', '#34A853'])\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "                     f'{height:.2f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "        plt.ylim(0, 1.1)\n",
        "        plt.title(f\"Probability Distribution\", fontsize=10)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save to buffer\n",
        "        buffer = io.BytesIO()\n",
        "        plt.savefig(buffer, format='png', dpi=80)\n",
        "        plt.close()\n",
        "\n",
        "        # Convert to base64 for embedding\n",
        "        buffer.seek(0)\n",
        "        img_str = base64.b64encode(buffer.read()).decode('utf-8')\n",
        "\n",
        "        return f'<img src=\"data:image/png;base64,{img_str}\" style=\"max-width:100%;\">'\n",
        "    except Exception as e:\n",
        "        # Return empty string if there's any error\n",
        "        return \"\"\n",
        "\n",
        "# Use the function to create and display the visualization\n",
        "# create_bayesian_network_with_probabilities(result_df)\n"
      ],
      "metadata": {
        "id": "WEd2_l73q7CN"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbRSd0SK5_sA"
      },
      "source": [
        "## 4.1 Network Visualizer: Data (.csv) to DAGs of Dynamic Bayes Nets (.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Function to convert our extracted data to pgmpy BayesianModel"
      ],
      "metadata": {
        "id": "23OWMfNEhZrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bayesian_network(df):\n",
        "    '''\n",
        "      Creates a pgmpy BayesianModel from extracted BayesDown dataArgs:\n",
        "          df: DataFrame containing extracted BayesDown data\n",
        "\n",
        "      Returns:\n",
        "          model: A pgmpy BayesianModel instance or None if creation fails\n",
        "    '''\n",
        "    # Create an empty Bayesian Network\n",
        "    edges = []\n",
        "\n",
        "    # Add edges based on parent-child relationships\n",
        "    for idx, row in df.iterrows():\n",
        "        node = row['Title']\n",
        "        parents = row['Parents']\n",
        "\n",
        "        # Check if parents is a list or a string representation of a list\n",
        "        if isinstance(parents, str):\n",
        "            try:\n",
        "                parents = eval(parents)  # Convert string representation to actual list\n",
        "            except:\n",
        "                parents = []\n",
        "\n",
        "        if isinstance(parents, list) and parents:\n",
        "            for parent in parents:\n",
        "                edges.append((parent, node))\n",
        "\n",
        "    # Create Bayesian Network with identified edges\n",
        "    if not edges:\n",
        "        print(\"Warning: No edges found in the data\")\n",
        "        return None\n",
        "\n",
        "    model = BayesianNetwork(edges)\n",
        "    print(f\"Created Bayesian Network with edges: {edges}\")\n",
        "\n",
        "    # Add CPDs (Conditional Probability Distributions)\n",
        "    for idx, row in df.iterrows():\n",
        "        node = row['Title']\n",
        "\n",
        "        # Extract variable states from instantiations\n",
        "        instantiations = row['instantiations']\n",
        "        if isinstance(instantiations, str):\n",
        "            try:\n",
        "                instantiations = eval(instantiations)  # Convert string representation to actual list\n",
        "            except:\n",
        "                instantiations = [\"TRUE\", \"FALSE\"]  # Default if conversion fails\n",
        "\n",
        "        # Number of possible states for this variable\n",
        "        var_states = len(instantiations) if isinstance(instantiations, list) else 2\n",
        "\n",
        "        # Get parents\n",
        "        parents = row['Parents']\n",
        "        if isinstance(parents, str):\n",
        "            try:\n",
        "                parents = eval(parents)\n",
        "            except:\n",
        "                parents = []\n",
        "\n",
        "        # If node has no parents, use prior probabilities\n",
        "        if not parents or len(parents) == 0:\n",
        "            priors = row['priors']\n",
        "            if isinstance(priors, str):\n",
        "                try:\n",
        "                    priors = eval(priors)\n",
        "                except:\n",
        "                    priors = {}\n",
        "\n",
        "            # Extract probability values\n",
        "            prob_values = []\n",
        "            if priors and isinstance(priors, dict):\n",
        "                for state in instantiations:\n",
        "                    key = f\"p({state})\"\n",
        "                    if key in priors:\n",
        "                        try:\n",
        "                            prob_values.append(float(priors[key]))\n",
        "                        except:\n",
        "                            prob_values.append(0.5)  # Default if conversion fails\n",
        "                    else:\n",
        "                        prob_values.append(0.5)  # Default if key not found\n",
        "\n",
        "            # If we don't have probabilities for all states or have none, use uniform distribution\n",
        "            if len(prob_values) != var_states or not prob_values:\n",
        "                prob_values = [1.0/var_states] * var_states\n",
        "\n",
        "            # Create the CPD for a node with no parents\n",
        "            cpd = TabularCPD(\n",
        "                variable=node,\n",
        "                variable_card=var_states,\n",
        "                values=[prob_values],\n",
        "                state_names={node: instantiations}\n",
        "            )\n",
        "            try:\n",
        "                model.add_cpds(cpd)\n",
        "                print(f\"Added CPD for node {node} with no parents\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error adding CPD for {node}: {e}\")\n",
        "\n",
        "        # If node has parents, use conditional probabilities\n",
        "        else:\n",
        "            posteriors = row['posteriors']\n",
        "            if isinstance(posteriors, str):\n",
        "                try:\n",
        "                    posteriors = eval(posteriors)\n",
        "                except:\n",
        "                    posteriors = {}\n",
        "\n",
        "            if posteriors and isinstance(posteriors, dict):\n",
        "                # This is a more complex case - we need to organize conditional probabilities\n",
        "                # based on parent configurations\n",
        "\n",
        "                # Get parent instantiations\n",
        "                parent_states = {}\n",
        "                for parent in parents:\n",
        "                    parent_row = df[df['Title'] == parent]\n",
        "                    if not parent_row.empty:\n",
        "                        parent_instantiations = parent_row.iloc[0]['instantiations']\n",
        "                        if isinstance(parent_instantiations, str):\n",
        "                            try:\n",
        "                                parent_instantiations = eval(parent_instantiations)\n",
        "                            except:\n",
        "                                parent_instantiations = [\"TRUE\", \"FALSE\"]\n",
        "                        parent_states[parent] = parent_instantiations\n",
        "                    else:\n",
        "                        parent_states[parent] = [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "                # Calculate parent cardinalities\n",
        "                parent_cards = [len(parent_states[parent]) for parent in parents]\n",
        "\n",
        "                # We need to convert the posteriors dict to the tabular format expected by pgmpy\n",
        "                # This is a simplified example that assumes binary variables and a specific\n",
        "                # format of the posteriors dict\n",
        "\n",
        "                # For demonstration, we'll create a CPD with uniform conditional probabilities\n",
        "                values = np.ones((var_states, np.prod(parent_cards))) / var_states\n",
        "\n",
        "                # In a real implementation, we would populate this based on the actual posteriors data\n",
        "                # The exact implementation would depend on the specific format of your posteriors data\n",
        "\n",
        "                cpd = TabularCPD(\n",
        "                    variable=node,\n",
        "                    variable_card=var_states,\n",
        "                    values=values,\n",
        "                    evidence=parents,\n",
        "                    evidence_card=parent_cards,\n",
        "                    state_names={node: instantiations}\n",
        "                )\n",
        "\n",
        "                try:\n",
        "                    model.add_cpds(cpd)\n",
        "                    print(f\"Added CPD for node {node} with parents {parents}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error adding CPD for {node}: {e}\")\n",
        "\n",
        "    # Check if the model is valid\n",
        "    try:\n",
        "        model.check_model()\n",
        "        print(\"Model is valid\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"Model validation failed: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "AcOFi9K8d-cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Function to perform inference on the Bayesian Network"
      ],
      "metadata": {
        "id": "XQc-M20rgzDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_inference(model, query_variables, evidence=None):\n",
        "  \"\"\"\n",
        "  Performs inference on the Bayesian Network\n",
        "  Args:\n",
        "      model: pgmpy BayesianModel\n",
        "      query_variables: List of variables to query\n",
        "      evidence: Dictionary of evidence (variable: value)\n",
        "\n",
        "  Returns:\n",
        "      results: Dictionary of query results\n",
        "  \"\"\"\n",
        "  if model is None:\n",
        "      print(\"Error: No valid model provided for inference\")\n",
        "      return {}\n",
        "\n",
        "  try:\n",
        "      inference = VariableElimination(model)\n",
        "\n",
        "      if evidence is None:\n",
        "          evidence = {}\n",
        "\n",
        "      results = {}\n",
        "      for variable in query_variables:\n",
        "          result = inference.query(variables=[variable], evidence=evidence)\n",
        "          results[variable] = result\n",
        "\n",
        "      return results\n",
        "  except Exception as e:\n",
        "      print(f\"Inference error: {e}\")\n",
        "      return {}"
      ],
      "metadata": {
        "id": "Vao2U4Aug3pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Function to visualize the Bayesian Network"
      ],
      "metadata": {
        "id": "IVFzIs6jd-Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_network(model, df):\n",
        "  \"\"\"\n",
        "  Creates a visualization of the Bayesian Network\n",
        "  Args:\n",
        "      model: pgmpy BayesianModel\n",
        "      df: DataFrame containing extracted BayesDown data\n",
        "\n",
        "  Returns:\n",
        "      Network object that can be displayed\n",
        "  \"\"\"\n",
        "  if model is None:\n",
        "      print(\"Error: No valid model provided for visualization\")\n",
        "      return None\n",
        "\n",
        "  # Create a pyvis network\n",
        "  net = Network(notebook=True, directed=True, height=\"500px\", width=\"100%\")\n",
        "\n",
        "  # Add nodes\n",
        "  for node in model.nodes():\n",
        "      # Find the node in df to get additional info\n",
        "      node_info = df[df['Title'] == node]\n",
        "      if not node_info.empty:\n",
        "          description = str(node_info.iloc[0]['Description'])\n",
        "\n",
        "          # Truncate description for label if it's too long\n",
        "          label = f\"{node}\\n{description[:30]}...\" if len(description) > 30 else f\"{node}\\n{description}\"\n",
        "\n",
        "          # Add node with title (hover text) containing full description\n",
        "          net.add_node(node, label=label, title=description, shape='box')\n",
        "      else:\n",
        "          net.add_node(node, label=node, shape='box')\n",
        "\n",
        "  # Add edges\n",
        "  for edge in model.edges():\n",
        "      net.add_edge(edge[0], edge[1], arrows='to')\n",
        "\n",
        "  # Set physics layout options for better visualization\n",
        "  net.barnes_hut(gravity=-80000, central_gravity=0.3, spring_length=100, spring_strength=0.01, damping=0.09)\n",
        "\n",
        "  return net"
      ],
      "metadata": {
        "id": "UZgXXvZ1hBao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Function to visualize probability distributions"
      ],
      "metadata": {
        "id": "CXJHuilPhIZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_probabilities(results, variable):\n",
        "  \"\"\"\n",
        "  Creates visualizations of probability distributions for a variable\n",
        "  Args:\n",
        "      results: Dictionary of inference results\n",
        "      variable: The variable to visualize\n",
        "\n",
        "  Returns:\n",
        "      None (displays the visualization)\n",
        "  \"\"\"\n",
        "  if not results or variable not in results:\n",
        "      print(f\"No results available for variable {variable}\")\n",
        "      return\n",
        "\n",
        "  result = results[variable]\n",
        "\n",
        "  # Extract the probability values\n",
        "  probs = result.values\n",
        "  states = result.state_names[variable]\n",
        "\n",
        "  # Create a bar chart\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.bar(states, probs)\n",
        "  plt.xlabel('States')\n",
        "  plt.ylabel('Probability')\n",
        "  plt.title(f'Probability Distribution for {variable}')\n",
        "  plt.ylim(0, 1)\n",
        "\n",
        "  for i, value in enumerate(probs):\n",
        "      plt.text(i, value + 0.02, f'{value:.3f}', ha='center')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ojViELvQhHzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJonCk9roi82"
      },
      "source": [
        "### 4.1.1 Visualize the Network\n",
        "Visualize the network (PDF) using matplotlib and networkx."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pZtEqt5n2BE"
      },
      "source": [
        "### 4.1.2 Display Graph in Colab as dynamic HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHQm7ydMmPhN"
      },
      "source": [
        "# 5.0 Archive_version_histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipmcopCbHFVt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjbIj19epbrF"
      },
      "source": [
        "# 6.0 Save Outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QqlN6dYpm4s"
      },
      "source": [
        "## Convert ipynb to HTML in Colab\n",
        "\n",
        "Instruction:\n",
        "\n",
        "Download the ipynb, which you want to convert, on your local computer.\n",
        "Run the code below to upload the ipynb.\n",
        "\n",
        "The html version will be downloaded automatically on your local machine.\n",
        "Enjoy it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "dWiHUcgWpuvx",
        "outputId": "eab45923-f47f-4831-8e6f-594405065728"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b6a1e23d-de39-45f4-8f7a-d0cefb02a746\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b6a1e23d-de39-45f4-8f7a-d0cefb02a746\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving AMTAIR_Prototype_0_1.2.ipynb to AMTAIR_Prototype_0_1.2.ipynb\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_39ee8571-3d4d-4ec8-864d-85d41b19389f\", \"AMTAIR_Prototype_0_1.2.html\", 458977)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Convert ipynb to HTML in Colab\n",
        "# Upload ipynb\n",
        "from google.colab import files\n",
        "f = files.upload()\n",
        "\n",
        "# Convert ipynb to html\n",
        "import subprocess\n",
        "file0 = list(f.keys())[0]\n",
        "_ = subprocess.run([\"pip\", \"install\", \"nbconvert\"])\n",
        "_ = subprocess.run([\"jupyter\", \"nbconvert\", file0, \"--to\", \"html\"])\n",
        "\n",
        "# download the html\n",
        "files.download(file0[:-5]+\"html\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "57YvCx9dom5J",
        "ZWx7CRfHn8Va",
        "mbRSd0SK5_sA"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}